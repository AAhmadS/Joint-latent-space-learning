{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c179557966bd4c288047cdf9e5b113fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e5adab3c6ab4ccf9da839d667ad9937",
              "IPY_MODEL_c73604aa558846bebf3269e4d36565a5",
              "IPY_MODEL_ca0c1ccca59f4fee85337f7a6fbcdaef"
            ],
            "layout": "IPY_MODEL_8fa104bd027749408a2809f9324b8c28"
          }
        },
        "5e5adab3c6ab4ccf9da839d667ad9937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f5e90c98c274bb6990c3341f1b1dc01",
            "placeholder": "​",
            "style": "IPY_MODEL_34bed69587bf4c909b0330d859cd61d7",
            "value": "100%"
          }
        },
        "c73604aa558846bebf3269e4d36565a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18c8d5ca8270424b96aec1a642f54ccd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a53ee24f34f4651b5288862faa28471",
            "value": 1
          }
        },
        "ca0c1ccca59f4fee85337f7a6fbcdaef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ca254ccafa9428fb0c9bffd4d0a806b",
            "placeholder": "​",
            "style": "IPY_MODEL_bccac87510e341ae90b94ef953a195be",
            "value": " 1/1 [00:00&lt;00:00, 15.11ba/s]"
          }
        },
        "8fa104bd027749408a2809f9324b8c28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f5e90c98c274bb6990c3341f1b1dc01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34bed69587bf4c909b0330d859cd61d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18c8d5ca8270424b96aec1a642f54ccd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a53ee24f34f4651b5288862faa28471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ca254ccafa9428fb0c9bffd4d0a806b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bccac87510e341ae90b94ef953a195be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbf5b7b3912044ea9f7d8d8d4767f0e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d1d50dc9ced4b4bb8a0b1dd109024c6",
              "IPY_MODEL_1785d71dfad34b229fc6ec8089d9fe7e",
              "IPY_MODEL_b78544d4404b4d43bff9eb0cb514cf40"
            ],
            "layout": "IPY_MODEL_b72046478a9e4f1e8c4383c638bd52d6"
          }
        },
        "2d1d50dc9ced4b4bb8a0b1dd109024c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8891de0f7de34db1a5ece76bbc3564cf",
            "placeholder": "​",
            "style": "IPY_MODEL_9d57bd3a1abf4e47bbadff3666fd7e24",
            "value": "100%"
          }
        },
        "1785d71dfad34b229fc6ec8089d9fe7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_435cddee955f4b1bb1ae76c18d5bada8",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c48c5d8ea29d422988977116694b7f91",
            "value": 21
          }
        },
        "b78544d4404b4d43bff9eb0cb514cf40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96ecf5a2a99b4b11b208a69cd2508c1c",
            "placeholder": "​",
            "style": "IPY_MODEL_d514c77a673242b686cb774b1744e414",
            "value": " 21/21 [00:00&lt;00:00, 64.82ba/s]"
          }
        },
        "b72046478a9e4f1e8c4383c638bd52d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8891de0f7de34db1a5ece76bbc3564cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d57bd3a1abf4e47bbadff3666fd7e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "435cddee955f4b1bb1ae76c18d5bada8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c48c5d8ea29d422988977116694b7f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96ecf5a2a99b4b11b208a69cd2508c1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d514c77a673242b686cb774b1744e414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dc7e4525e244b2da8cabdfa46821b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0909e176b57a45f6b2e182df0ae98009",
              "IPY_MODEL_a2ea7e5bb80c4af5a28e7aecc0189c5d",
              "IPY_MODEL_d9da062a88e14e16aa36e0050bf1aad4"
            ],
            "layout": "IPY_MODEL_13f0f4f0b116476f9912ba7c4d6e7114"
          }
        },
        "0909e176b57a45f6b2e182df0ae98009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0694fcc509d42aba7e35a7859f53ef1",
            "placeholder": "​",
            "style": "IPY_MODEL_b0fecafdb172469eba558c7b8a170ba9",
            "value": "100%"
          }
        },
        "a2ea7e5bb80c4af5a28e7aecc0189c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73daf449acc34d2ab904fa1c2dab58c9",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c312a3d2fbf24bbaa78dc8ba2e4bc08a",
            "value": 5
          }
        },
        "d9da062a88e14e16aa36e0050bf1aad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39eb936e319b412dbb6eedbab27a959d",
            "placeholder": "​",
            "style": "IPY_MODEL_f65713a01759443ab745bc67cf25699d",
            "value": " 5/5 [00:00&lt;00:00, 107.40ba/s]"
          }
        },
        "13f0f4f0b116476f9912ba7c4d6e7114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0694fcc509d42aba7e35a7859f53ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0fecafdb172469eba558c7b8a170ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73daf449acc34d2ab904fa1c2dab58c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c312a3d2fbf24bbaa78dc8ba2e4bc08a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39eb936e319b412dbb6eedbab27a959d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f65713a01759443ab745bc67cf25699d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AAhmadS/NLP-HW3/blob/main/NLP_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycCs7DfEpX1u"
      },
      "source": [
        "## Install and import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jtkeu_Wx0ai",
        "outputId": "c24668d3-9b0c-4ab8-a7df-d0c9f4c77903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/TasnimDataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DCVttnZJ5OG",
        "outputId": "f6fbccd7-ad93-48a9-9135-c0d4f2a2145f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1WC54iNX9iiUwBMeH0jXlgq2JSuERNvwm/TasnimDataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dill==0.3.5.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSa7PGTJWlJn",
        "outputId": "38d8505f-8d01-40c3-891a-b5ba91f71654"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dill==0.3.5.1 in /usr/local/lib/python3.10/dist-packages (0.3.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0BpdJkdBssk9"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers==4.0.1\n",
        "! pip install ftfy regex tqdm\n",
        "! pip install arabic-reshaper\n",
        "! pip install python-bidi\n",
        "! pip install dadmatools\n",
        "!pip install -Uq g2p_en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C1hkDT38hSaP",
        "outputId": "dd737be7-4df6-4da5-98c5-aa6d50889da0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 2.0.1+cu118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-6bc956d93c61>:37: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
            "  from scipy.ndimage.filters import gaussian_filter\n"
          ]
        }
      ],
      "source": [
        "from __future__ import unicode_literals\n",
        "# from hazm import Normalizer as hNormalizer\n",
        "from dadmatools.models.normalizer import Normalizer as dNormalizer\n",
        "import gc\n",
        "import time\n",
        "import copy\n",
        "import PIL\n",
        "import torch\n",
        "import os\n",
        "import dill\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import multiprocessing\n",
        "from tqdm import tqdm\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "from pkg_resources import packaging\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from matplotlib.font_manager import FontProperties\n",
        "from bidi.algorithm import get_display\n",
        "from arabic_reshaper import reshape\n",
        "from torch.cuda.amp import autocast\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoModel, AutoTokenizer, AutoModel, TFAutoModel, AutoConfig\n",
        "from transformers import EncoderDecoderModel\n",
        "from transformers import GPT2LMHeadModel, GPT2Config\n",
        "from transformers import BertGenerationConfig, BertGenerationEncoder\n",
        "from transformers import BertModel\n",
        "from transformers import TrainingArguments, Trainer, RobertaModel\n",
        "from transformers import default_data_collator\n",
        "from IPython.display import clear_output\n",
        "import seaborn as sns\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "import tqdm\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelWithLMHead\n",
        "from transformers import AutoTokenizer, GPT2LMHeadModel, GPT2Config\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "# persian_font = FontProperties(fname='/content/fonts/Vazirmatn-Regular.ttf')\n",
        "# \n",
        "print(\"Torch version:\", torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq hazm\n",
        "\n",
        "import hazm\n",
        "normalizer = hazm.Normalizer(persian_numbers=False)\n",
        "\n",
        "def normalize_input(text):\n",
        "  text = noramlizer.normalize(text)\n",
        "  return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K20btDTkPGVd",
        "outputId": "79a39772-972c-469b-be83-7ed5fc717547"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**So basically we are going to train an encoder-decoder model based on our natural language data to have good enough text encoder and general decoder, next step is to bring on the vision model and connect the vision encoder to the trained decoder, now the decoder part is going to freeze and the vision encoder is going to learn the latent space pretty well**"
      ],
      "metadata": {
        "id": "sCAUWIz-_JDX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQT2E9PoWKAn"
      },
      "source": [
        "## Defining the ML-Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading the models"
      ],
      "metadata": {
        "id": "DNifsnpO-42z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First we should manage to train our nlp enc-dec model, we've chosen Parsebert and ParsGPT for the task**"
      ],
      "metadata": {
        "id": "IFysCfMo_ErV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l79DaXF9WKAo",
        "outputId": "8f0ba8e8-3c13-430b-dc7b-94d18c359edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vOKzv2bCWKAo",
        "outputId": "7d407419-092a-4997-8e62-b43b6b89e3e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-06 02:21:18--  https://huggingface.co/HooshvareLab/gpt2-fa/resolve/main/pytorch_model.bin\n",
            "Resolving huggingface.co (huggingface.co)... 18.67.0.90, 18.67.0.34, 18.67.0.67, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.67.0.90|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/HooshvareLab/gpt2-fa/46b0b806c740a0f0a9f056f5574c5fa896166fe844945fd3c849bf34365e5060?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1686277279&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL0hvb3NodmFyZUxhYi9ncHQyLWZhLzQ2YjBiODA2Yzc0MGEwZjBhOWYwNTZmNTU3NGM1ZmE4OTYxNjZmZTg0NDk0NWZkM2M4NDliZjM0MzY1ZTUwNjA%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjg2Mjc3Mjc5fX19XX0_&Signature=X3bjaNDPUPkvd6T-NeLsvB0B7aOXQq4YCnHPRRWXnI8ELwXD-yX7FsBs5EuOhhEki-NzipmGeNqyvJiVjpxcIQp1LK565qkRp0QH5sxj-%7EvEHut1cUdEw%7E0U45fZJfpyZ1nQSSmVg4eZQ1jnUE1HqmuW%7EfCHY53Wil%7E%7E5UkbXCqibR2fSTPQJsBlyneeGf2w4MAGEYSNdG0ywmosfBMbjU6jWydibyYpG4nwtU%7EHw6ooCLB16oVNsNbWi9zG6j94iDZ1fBcgGWKT5owsq5PfuuytxqeUI-pLJS0IZ5ssw8AGyRW6DvdaLsjwxD2I%7Eonsa1Cwc7gWi00DwRXFtpdvnA__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-06-06 02:21:18--  https://cdn-lfs.huggingface.co/HooshvareLab/gpt2-fa/46b0b806c740a0f0a9f056f5574c5fa896166fe844945fd3c849bf34365e5060?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1686277279&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL0hvb3NodmFyZUxhYi9ncHQyLWZhLzQ2YjBiODA2Yzc0MGEwZjBhOWYwNTZmNTU3NGM1ZmE4OTYxNjZmZTg0NDk0NWZkM2M4NDliZjM0MzY1ZTUwNjA%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjg2Mjc3Mjc5fX19XX0_&Signature=X3bjaNDPUPkvd6T-NeLsvB0B7aOXQq4YCnHPRRWXnI8ELwXD-yX7FsBs5EuOhhEki-NzipmGeNqyvJiVjpxcIQp1LK565qkRp0QH5sxj-%7EvEHut1cUdEw%7E0U45fZJfpyZ1nQSSmVg4eZQ1jnUE1HqmuW%7EfCHY53Wil%7E%7E5UkbXCqibR2fSTPQJsBlyneeGf2w4MAGEYSNdG0ywmosfBMbjU6jWydibyYpG4nwtU%7EHw6ooCLB16oVNsNbWi9zG6j94iDZ1fBcgGWKT5owsq5PfuuytxqeUI-pLJS0IZ5ssw8AGyRW6DvdaLsjwxD2I%7Eonsa1Cwc7gWi00DwRXFtpdvnA__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.64.174.106, 18.64.174.110, 18.64.174.43, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.64.174.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 485044198 (463M) [application/octet-stream]\n",
            "Saving to: ‘/content/gpt2/pytorch_model.bin.4’\n",
            "\n",
            "pytorch_model.bin.4 100%[===================>] 462.57M   143MB/s    in 3.4s    \n",
            "\n",
            "2023-06-06 02:21:22 (138 MB/s) - ‘/content/gpt2/pytorch_model.bin.4’ saved [485044198/485044198]\n",
            "\n",
            "--2023-06-06 02:21:22--  https://huggingface.co/HooshvareLab/gpt2-fa/resolve/main/tokenizer.json\n",
            "Resolving huggingface.co (huggingface.co)... 18.67.0.90, 18.67.0.34, 18.67.0.67, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.67.0.90|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2748949 (2.6M) [text/plain]\n",
            "Saving to: ‘/content/gpt2/tokenizer.json.5’\n",
            "\n",
            "tokenizer.json.5    100%[===================>]   2.62M  16.5MB/s    in 0.2s    \n",
            "\n",
            "2023-06-06 02:21:22 (16.5 MB/s) - ‘/content/gpt2/tokenizer.json.5’ saved [2748949/2748949]\n",
            "\n",
            "--2023-06-06 02:21:23--  https://huggingface.co/HooshvareLab/bert-fa-base-uncased-clf-persiannews/resolve/main/pytorch_model.bin\n",
            "Resolving huggingface.co (huggingface.co)... 18.67.0.90, 18.67.0.34, 18.67.0.67, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.67.0.90|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/HooshvareLab/bert-fa-base-uncased-clf-persiannews/c6dd3d8d00488930f31d6d9ec1b49533a4603454f61e1aa8067dc01cdcc7a4e2?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1686275838&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL0hvb3NodmFyZUxhYi9iZXJ0LWZhLWJhc2UtdW5jYXNlZC1jbGYtcGVyc2lhbm5ld3MvYzZkZDNkOGQwMDQ4ODkzMGYzMWQ2ZDllYzFiNDk1MzNhNDYwMzQ1NGY2MWUxYWE4MDY3ZGMwMWNkY2M3YTRlMj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODYyNzU4Mzh9fX1dfQ__&Signature=cFgu21AIi5S5I9rllWDoNKK7JpUA2FjhKUUzgka2AL-%7Eq9TiVnfFBIACCB5CsOJUzHjWI0-7jOwuCOFbFlAvkcp9JKS0h21-DPiZWIIkHtcFwvPzTbTf5oTTfwPdMFyI5CB1dCjVQ5RT5khjYKn5VhIvMWKgaIuua9vMN-PIjOEamT9taf7ZpqzWlIrMGHmvxumtgtYzh6Sgq5a16zpKx1ZinYIKE4rcV30uX36w3gHZx5V%7ERjLmtNxaY8VGmf3mqecNUCbSnoYOiRNfVlAQtPtScaA-vw6KQCGP%7EGI7VN8%7Eb5wyI0harvv4pLj8JhdTecW6DS2FO%7EdzG7w1F1SHiw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-06-06 02:21:23--  https://cdn-lfs.huggingface.co/HooshvareLab/bert-fa-base-uncased-clf-persiannews/c6dd3d8d00488930f31d6d9ec1b49533a4603454f61e1aa8067dc01cdcc7a4e2?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1686275838&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL0hvb3NodmFyZUxhYi9iZXJ0LWZhLWJhc2UtdW5jYXNlZC1jbGYtcGVyc2lhbm5ld3MvYzZkZDNkOGQwMDQ4ODkzMGYzMWQ2ZDllYzFiNDk1MzNhNDYwMzQ1NGY2MWUxYWE4MDY3ZGMwMWNkY2M3YTRlMj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODYyNzU4Mzh9fX1dfQ__&Signature=cFgu21AIi5S5I9rllWDoNKK7JpUA2FjhKUUzgka2AL-%7Eq9TiVnfFBIACCB5CsOJUzHjWI0-7jOwuCOFbFlAvkcp9JKS0h21-DPiZWIIkHtcFwvPzTbTf5oTTfwPdMFyI5CB1dCjVQ5RT5khjYKn5VhIvMWKgaIuua9vMN-PIjOEamT9taf7ZpqzWlIrMGHmvxumtgtYzh6Sgq5a16zpKx1ZinYIKE4rcV30uX36w3gHZx5V%7ERjLmtNxaY8VGmf3mqecNUCbSnoYOiRNfVlAQtPtScaA-vw6KQCGP%7EGI7VN8%7Eb5wyI0harvv4pLj8JhdTecW6DS2FO%7EdzG7w1F1SHiw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.64.174.106, 18.64.174.110, 18.64.174.43, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.64.174.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 651477729 (621M) [application/octet-stream]\n",
            "Saving to: ‘huggingface.co/HooshvareLab/bert-fa-base-uncased-clf-persiannews/resolve/main/pytorch_model.bin’\n",
            "\n",
            "huggingface.co/Hoos 100%[===================>] 621.30M  40.8MB/s    in 18s     \n",
            "\n",
            "2023-06-06 02:21:41 (34.7 MB/s) - ‘huggingface.co/HooshvareLab/bert-fa-base-uncased-clf-persiannews/resolve/main/pytorch_model.bin’ saved [651477729/651477729]\n",
            "\n",
            "/content/bert/: Scheme missing.\n",
            "FINISHED --2023-06-06 02:21:41--\n",
            "Total wall clock time: 19s\n",
            "Downloaded: 1 files, 621M in 18s (34.7 MB/s)\n"
          ]
        }
      ],
      "source": [
        "##loading the gpt and bert model\n",
        "gpt_name_or_path = \"HooshvareLab/gpt2-fa\"\n",
        "bert_name_or_path = \"HooshvareLab/bert-fa-base-uncased-clf-persiannews\"\n",
        "##we wil stick to gpt tokenizer as our chosen tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    gpt_name_or_path,\n",
        "    bos_token='<s>', \n",
        "    eos_token='</s>', \n",
        "    pad_token='<pad>',\n",
        "    unk_token='<unk>'\n",
        ")\n",
        "tokenizer.add_special_tokens({\n",
        "    \"bos_token\": '</s>',\n",
        "    \"eos_token\": '</s>', \n",
        "    \"pad_token\": '<pad>',\n",
        "    \"unk_token\": '<unk>'\n",
        "})\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    gpt_name_or_path,\n",
        "    bos_token_id=tokenizer(\"<s>\")[\"input_ids\"][0], \n",
        "    eos_token_id=tokenizer(\"</s>\")[\"input_ids\"][0], \n",
        "    pad_token_id=tokenizer(\"<pad>\")[\"input_ids\"][0],\n",
        "    unk_token_id=tokenizer(\"<unk>\")[\"input_ids\"][0],\n",
        ")\n",
        "\n",
        "bert_config = AutoConfig.from_pretrained(bert_name_or_path)\n",
        "\n",
        "##saving the config on the drive\n",
        "tokenizer.save_pretrained(\"/content/gpt2/\")\n",
        "config.save_pretrained(\"/content/gpt2/\")\n",
        "bert_config.save_pretrained(\"/content/bert/\")\n",
        "\n",
        "!wget \"https://huggingface.co/HooshvareLab/gpt2-fa/resolve/main/pytorch_model.bin\" -P /content/gpt2/\n",
        "!wget \"https://huggingface.co/HooshvareLab/gpt2-fa/resolve/main/tokenizer.json\" -P /content/gpt2/\n",
        "!wget \"https://huggingface.co/HooshvareLab/bert-fa-base-uncased-clf-persiannews/resolve/main/pytorch_model.bin\" -p /content/bert/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ete0nQRLMl1J"
      },
      "source": [
        "####Suitable data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets==1.0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRUniorwTzaA",
        "outputId": "1c2817b9-4e44-4981-ec18-791e4c9f0cf1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets==1.0.2 in /usr/local/lib/python3.10/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==1.0.2) (1.24.3)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from datasets==1.0.2) (9.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from datasets==1.0.2) (0.3.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==1.0.2) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==1.0.2) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from datasets==1.0.2) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==1.0.2) (3.12.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==1.0.2) (3.2.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.0.2) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.0.2) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.0.2) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.0.2) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==1.0.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==1.0.2) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==1.0.2) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "f=open(\"news.json\")\n",
        "news=json.load(f)"
      ],
      "metadata": {
        "id": "rLmbX06qUp-A"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_description_list_final=[]\n",
        "text_title_list_final=[]\n",
        "images_list_final=[]\n",
        "for item in news:\n",
        "  for image in item.get(\"images\"):\n",
        "    if image==\"1400070516181726323700473.jpg\":\n",
        "      continue\n",
        "    try:\n",
        "      open(\"images/\"+image,\"rb\")\n",
        "      text_description_list_final.append(item.get(\"description\"))\n",
        "      text_title_list_final.append(item.get(\"title\"))\n",
        "      images_list_final.append(\"images/\"+image)\n",
        "    except(FileNotFoundError, IOError):\n",
        "      continue"
      ],
      "metadata": {
        "id": "23HA_SsFYUgc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist([len(tokenizer.encode(text)) for text in text_title_list_final],color='g')\n",
        "plt.title(\"sentence length frequency\")\n",
        "plt.ylabel(\"number of sentences\")\n",
        "plt.xlabel(\"sentence length\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "sM3BTYOBdYU2",
        "outputId": "1fb5b418-d220-40a2-c602-10e0ca0c1789"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq = max([len(tokenizer.encode(text)) for text in text_title_list_final])\n",
        "\n",
        "print(f'The longest text is {max_seq} tokens long.')\n",
        "max_seq = 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_N53QcscLIy",
        "outputId": "64bbc8c4-3a1b-4af7-9f8f-afbef7ce6564"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest text is 23 tokens long.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "all_df = pd.DataFrame({'input': list(set(text_title_list_final)),\"output\" : list(set(text_title_list_final))})\n",
        "\n",
        "train_df, val_df = train_test_split(all_df, test_size=0.05, shuffle=True, random_state=42)\n",
        "\n",
        "train_data = Dataset.from_pandas(train_df)\n",
        "val_data= Dataset.from_pandas(val_df)"
      ],
      "metadata": {
        "id": "iiHdbFnzPpZr"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "vision_data = pd.DataFrame({'images': images_list_final , 'output' : text_title_list_final})\n",
        "\n",
        "nlp_data = pd.DataFrame({'input':list(set(text_title_list_final)),'output' : list(set(text_title_list_final))})\n",
        "\n",
        "display(HTML(nlp_data[:10].to_html()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "oKc_RlX7GoCe",
        "outputId": "abf512e3-4bbe-44b9-b0ac-86657de779cd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>مزارع کلزا در خراسان شمالی</td>\n",
              "      <td>مزارع کلزا در خراسان شمالی</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>برداشت عسل در جم - بوشهر</td>\n",
              "      <td>برداشت عسل در جم - بوشهر</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>نشست تخصصی واکاوی عملیات ثامن‌الائمه (ع)</td>\n",
              "      <td>نشست تخصصی واکاوی عملیات ثامن‌الائمه (ع)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>اختتامیه نمایشگاه و همایش بین المللی خوشنویسی راه ابریشم</td>\n",
              "      <td>اختتامیه نمایشگاه و همایش بین المللی خوشنویسی راه ابریشم</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>پیاده روی زائران حرم مطهر امام رضا (ع)</td>\n",
              "      <td>پیاده روی زائران حرم مطهر امام رضا (ع)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>محله های تهران - شوش</td>\n",
              "      <td>محله های تهران - شوش</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>اینجا چراغی روشن است ...</td>\n",
              "      <td>اینجا چراغی روشن است ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>مواجهه با مرگ در شمایل بنر</td>\n",
              "      <td>مواجهه با مرگ در شمایل بنر</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>پایدار در روشنایی</td>\n",
              "      <td>پایدار در روشنایی</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>نماز عید قربان در حرم حضرت معصومه (س)</td>\n",
              "      <td>نماز عید قربان در حرم حضرت معصومه (س)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wakECgirV1ZN"
      },
      "source": [
        "# map article and summary len to dict as well as if sample is longer than 16 tokens\n",
        "def map_to_length(x):\n",
        "  x[\"out_len\"] = len(tokenizer(x[\"output\"]).input_ids)\n",
        "  x[\"out_longer_16\"] = int(x[\"out_len\"] > 16)\n",
        "  return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ay_md7BUe_p",
        "outputId": "cd4a7e78-200b-4c9e-e680-f2c451d36f1e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetInfo(description='', citation='', homepage='', license='', features={'input': Value(dtype='string', id=None), 'output': Value(dtype='string', id=None), '__index_level_0__': Value(dtype='int64', id=None)}, post_processed=None, supervised_keys=None, builder_name=None, config_name=None, version=None, splits=None, download_checksums=None, download_size=None, post_processing_size=None, dataset_size=None, size_in_bytes=None)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yAVH5fkMwLr"
      },
      "source": [
        "sample_size = 0.95 * len(images_list_final)\n",
        "data_stats = train_data.select(range(1000)).map(map_to_length, num_proc=4)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kALWVxHlOU4A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c179557966bd4c288047cdf9e5b113fb",
            "5e5adab3c6ab4ccf9da839d667ad9937",
            "c73604aa558846bebf3269e4d36565a5",
            "ca0c1ccca59f4fee85337f7a6fbcdaef",
            "8fa104bd027749408a2809f9324b8c28",
            "0f5e90c98c274bb6990c3341f1b1dc01",
            "34bed69587bf4c909b0330d859cd61d7",
            "18c8d5ca8270424b96aec1a642f54ccd",
            "0a53ee24f34f4651b5288862faa28471",
            "1ca254ccafa9428fb0c9bffd4d0a806b",
            "bccac87510e341ae90b94ef953a195be"
          ]
        },
        "outputId": "80d4b2e5-c70f-4306-d1c8-46e0266dde72"
      },
      "source": [
        "def compute_and_print_stats(x):\n",
        "  if len(x[\"out_len\"]) == sample_size:\n",
        "    print(\n",
        "        \"output Mean: {}, %-titles > 16:{}\".format(\n",
        "            sum(x[\"article_len\"]) / sample_size,\n",
        "            sum(x[\"article_longer_512\"]) / sample_size, \n",
        "        )\n",
        "    )\n",
        "\n",
        "output = data_stats.map(\n",
        "  compute_and_print_stats, \n",
        "  batched=True,\n",
        "  batch_size=-1,\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c179557966bd4c288047cdf9e5b113fb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvv9SIKvYhd0",
        "outputId": "1a9bfc50-882e-4ae2-f3b9-e6fd824f69e0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset(features: {'__index_level_0__': Value(dtype='int64', id=None), 'input': Value(dtype='string', id=None), 'out_len': Value(dtype='int64', id=None), 'out_longer_16': Value(dtype='int64', id=None), 'output': Value(dtype='string', id=None)}, num_rows: 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoN2q0hZUbXN"
      },
      "source": [
        "encoder_max_length=max_seq\n",
        "decoder_max_length=max_seq\n",
        "\n",
        "def process_data_to_model_inputs(batch):\n",
        "  # tokenize the inputs and labels\n",
        "  inputs = tokenizer(batch[\"input\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
        "  outputs = tokenizer(batch[\"output\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
        "\n",
        "  batch[\"input_ids\"] = inputs.input_ids\n",
        "  batch[\"attention_mask\"] = inputs.attention_mask\n",
        "  batch[\"decoder_input_ids\"] = outputs.input_ids\n",
        "  batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
        "  batch[\"labels\"] = outputs.input_ids.copy()\n",
        "\n",
        "  # because BERT automatically shifts the labels, the labels correspond exactly to `decoder_input_ids`. \n",
        "  # We have to make sure that the PAD token is ignored\n",
        "  batch[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n",
        "\n",
        "  return batch"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z396M38-beJE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "dbf5b7b3912044ea9f7d8d8d4767f0e2",
            "2d1d50dc9ced4b4bb8a0b1dd109024c6",
            "1785d71dfad34b229fc6ec8089d9fe7e",
            "b78544d4404b4d43bff9eb0cb514cf40",
            "b72046478a9e4f1e8c4383c638bd52d6",
            "8891de0f7de34db1a5ece76bbc3564cf",
            "9d57bd3a1abf4e47bbadff3666fd7e24",
            "435cddee955f4b1bb1ae76c18d5bada8",
            "c48c5d8ea29d422988977116694b7f91",
            "96ecf5a2a99b4b11b208a69cd2508c1c",
            "d514c77a673242b686cb774b1744e414",
            "7dc7e4525e244b2da8cabdfa46821b39",
            "0909e176b57a45f6b2e182df0ae98009",
            "a2ea7e5bb80c4af5a28e7aecc0189c5d",
            "d9da062a88e14e16aa36e0050bf1aad4",
            "13f0f4f0b116476f9912ba7c4d6e7114",
            "c0694fcc509d42aba7e35a7859f53ef1",
            "b0fecafdb172469eba558c7b8a170ba9",
            "73daf449acc34d2ab904fa1c2dab58c9",
            "c312a3d2fbf24bbaa78dc8ba2e4bc08a",
            "39eb936e319b412dbb6eedbab27a959d",
            "f65713a01759443ab745bc67cf25699d"
          ]
        },
        "outputId": "6bb2bf58-84bc-40b9-b2c2-b95853d96810"
      },
      "source": [
        "batch_size=64\n",
        "\n",
        "train_data = train_data.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True, \n",
        "    batch_size=batch_size, \n",
        "    remove_columns=[\"input\", \"output\",\"__index_level_0__\"]\n",
        ")\n",
        "\n",
        "val_data = val_data.map(\n",
        "    process_data_to_model_inputs,\n",
        "    batched=True,\n",
        "    batch_size=16,\n",
        "    remove_columns = [\"input\",\"output\",\"__index_level_0__\"]\n",
        ")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/21 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbf5b7b3912044ea9f7d8d8d4767f0e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dc7e4525e244b2da8cabdfa46821b39"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFBL22RxsN1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aeb998d-5e6b-499c-90bc-eee70e89de20"
      },
      "source": [
        "train_data"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset(features: {'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'decoder_attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'decoder_input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}, num_rows: 1313)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vZKuZVvqxlC"
      },
      "source": [
        "train_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB-bX6qktl1i"
      },
      "source": [
        "val_data.set_format(\n",
        "    typt=\"torch\" , columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Loading the nlp model"
      ],
      "metadata": {
        "id": "W7_jfaHEAEv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert2bert = EncoderDecoderModel.from_encoder_decoder_pretrained(bert_name_or_path,gpt_name_or_path).float()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iBgzrfCDhXB",
        "outputId": "fe79937e-1176-4e7c-9f78-5cb5579b33d9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased-clf-persiannews were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at HooshvareLab/gpt2-fa and are newly initialized: ['transformer.h.7.crossattention.c_attn.weight', 'transformer.h.5.crossattention.c_proj.bias', 'transformer.h.2.crossattention.masked_bias', 'transformer.h.11.crossattention.q_attn.weight', 'transformer.h.8.crossattention.c_attn.weight', 'transformer.h.1.crossattention.c_proj.weight', 'transformer.h.0.crossattention.q_attn.weight', 'transformer.h.7.crossattention.bias', 'transformer.h.8.crossattention.masked_bias', 'transformer.h.5.crossattention.masked_bias', 'transformer.h.3.crossattention.masked_bias', 'transformer.h.5.crossattention.c_attn.weight', 'transformer.h.4.crossattention.q_attn.weight', 'transformer.h.9.ln_cross_attn.weight', 'transformer.h.6.crossattention.q_attn.weight', 'transformer.h.7.crossattention.q_attn.weight', 'transformer.h.5.crossattention.c_proj.weight', 'transformer.h.5.crossattention.bias', 'transformer.h.7.crossattention.c_proj.bias', 'transformer.h.11.crossattention.bias', 'transformer.h.11.crossattention.masked_bias', 'transformer.h.6.crossattention.masked_bias', 'transformer.h.6.crossattention.bias', 'transformer.h.9.crossattention.masked_bias', 'transformer.h.3.crossattention.c_proj.weight', 'transformer.h.9.crossattention.c_proj.weight', 'transformer.h.8.crossattention.c_proj.weight', 'transformer.h.1.crossattention.c_proj.bias', 'transformer.h.3.ln_cross_attn.weight', 'transformer.h.1.crossattention.c_attn.weight', 'transformer.h.5.ln_cross_attn.weight', 'transformer.h.2.crossattention.c_proj.weight', 'transformer.h.4.crossattention.c_proj.weight', 'transformer.h.8.crossattention.c_proj.bias', 'transformer.h.5.crossattention.q_attn.weight', 'transformer.h.4.crossattention.c_proj.bias', 'transformer.h.11.crossattention.c_proj.bias', 'transformer.h.6.crossattention.c_proj.bias', 'transformer.h.7.ln_cross_attn.weight', 'transformer.h.1.crossattention.q_attn.weight', 'transformer.h.3.crossattention.q_attn.weight', 'transformer.h.4.crossattention.masked_bias', 'transformer.h.6.ln_cross_attn.weight', 'transformer.h.4.crossattention.bias', 'transformer.h.8.ln_cross_attn.weight', 'transformer.h.0.crossattention.bias', 'transformer.h.8.crossattention.bias', 'transformer.h.3.crossattention.c_proj.bias', 'transformer.h.0.ln_cross_attn.weight', 'transformer.h.4.ln_cross_attn.weight', 'transformer.h.10.crossattention.c_proj.weight', 'transformer.h.0.crossattention.c_proj.bias', 'transformer.h.3.crossattention.c_attn.weight', 'transformer.h.2.crossattention.q_attn.weight', 'transformer.h.1.ln_cross_attn.weight', 'transformer.h.8.crossattention.q_attn.weight', 'transformer.h.10.crossattention.c_attn.weight', 'transformer.h.0.crossattention.masked_bias', 'transformer.h.2.crossattention.c_proj.bias', 'transformer.h.3.crossattention.bias', 'transformer.h.10.crossattention.q_attn.weight', 'transformer.h.10.crossattention.masked_bias', 'transformer.h.7.crossattention.c_proj.weight', 'transformer.h.6.crossattention.c_proj.weight', 'transformer.h.9.crossattention.bias', 'transformer.h.0.crossattention.c_attn.weight', 'transformer.h.9.crossattention.c_proj.bias', 'transformer.h.1.crossattention.masked_bias', 'transformer.h.4.crossattention.c_attn.weight', 'transformer.h.2.crossattention.c_attn.weight', 'transformer.h.10.crossattention.c_proj.bias', 'transformer.h.0.crossattention.c_proj.weight', 'transformer.h.2.crossattention.bias', 'transformer.h.10.ln_cross_attn.weight', 'transformer.h.11.crossattention.c_attn.weight', 'transformer.h.1.crossattention.bias', 'transformer.h.7.crossattention.masked_bias', 'transformer.h.9.crossattention.q_attn.weight', 'transformer.h.6.crossattention.c_attn.weight', 'transformer.h.2.ln_cross_attn.weight', 'transformer.h.9.crossattention.c_attn.weight', 'transformer.h.11.crossattention.c_proj.weight', 'transformer.h.10.crossattention.bias', 'transformer.h.11.ln_cross_attn.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert2bert.config.decoder_start_token_id = tokenizer.bos_token_id\n",
        "bert2bert.config.eos_token_id = tokenizer.eos_token_id\n",
        "bert2bert.config.pad_token_id = tokenizer.pad_token_id\n",
        "bert2bert.config.vocab_size = bert2bert.config.encoder.vocab_size"
      ],
      "metadata": {
        "id": "0Yw-wS4QDhTj"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert2bert.config.max_length = 16\n",
        "bert2bert.config.min_length = 2\n",
        "bert2bert.config.no_repeat_ngram_size = 3\n",
        "bert2bert.config.early_stopping = True\n",
        "bert2bert.config.length_penalty = 2.0\n",
        "bert2bert.config.num_beams = 4"
      ],
      "metadata": {
        "id": "kqmyO2eZEB-t"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!rm seq2seq_trainer.py\n",
        "!rm seq2seq_training_args.py\n",
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/seq2seq/seq2seq_trainer.py\n",
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/seq2seq/seq2seq_training_args.py"
      ],
      "metadata": {
        "id": "GCs5GmMLEMeg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install git-python==1.0.3\n",
        "!pip install rouge_score\n",
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "m10TYMvtEjzv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "from transformers import Seq2SeqTrainingArguments"
      ],
      "metadata": {
        "id": "RRCu1wCVEmdl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade accelerate\n",
        "!pip install transformers accelerate\n",
        "!pip install git+https://github.com/huggingface/accelerate\n",
        "!pip install transformers==4.28.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSbWVnAUZj3u",
        "outputId": "4fca037d-c219-4657-821d-9245b25b54dd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.20.0.dev0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.20.0.dev0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/accelerate\n",
            "  Cloning https://github.com/huggingface/accelerate to /tmp/pip-req-build-jl9w91jc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-req-build-jl9w91jc\n",
            "  Resolved https://github.com/huggingface/accelerate to commit b9628f13c26944eee29ccf5d718352279963cc17\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.0.dev0) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.0.dev0) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.0.dev0) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.0.dev0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.0.dev0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.0.dev0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.20.0.dev0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.20.0.dev0) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate==0.20.0.dev0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate==0.20.0.dev0) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==4.28.0 in /usr/local/lib/python3.10/dist-packages (4.28.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=int(batch_size/4),\n",
        "    fp16=True, \n",
        "    output_dir=\"/content/TasnimDataset/models\",\n",
        "    logging_steps=2,\n",
        "    save_steps=5,\n",
        "    eval_steps=4\n",
        ")"
      ],
      "metadata": {
        "id": "Lj2Eme_9Eo4j"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets"
      ],
      "metadata": {
        "id": "axSi8yrUdTMG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = datasets.load_metric(\"rouge\")"
      ],
      "metadata": {
        "id": "skBR5ZHtFBkY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
        "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
        "\n",
        "    return {\n",
        "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
        "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
        "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
        "    }"
      ],
      "metadata": {
        "id": "t3yv70KYFHVm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.23.4"
      ],
      "metadata": {
        "id": "bAjcv_Pcf5ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert2bert.to(device)\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=bert2bert,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "7ZFXf-6wFMcx",
        "outputId": "c67931ba-9da2-4799-ee9f-2d95ed325fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11/63 00:48 < 04:40, 0.19 it/s, Epoch 0.48/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge2 Precision</th>\n",
              "      <th>Rouge2 Recall</th>\n",
              "      <th>Rouge2 Fmeasure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.494500</td>\n",
              "      <td>11.763989</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.266900</td>\n",
              "      <td>12.910440</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "uF_B626XgdhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_bert2bert = EncoderDecoderModel.from_pretrained(\"./checkpoint-20\")"
      ],
      "metadata": {
        "id": "jkIR4E96gfQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnlqXa1SWKAo"
      },
      "source": [
        "###using the models trained in the last section, now we will use Clip's vision part as our vision encoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Loading the model configuration and setting it to the GPT2 standard settings.\n",
        "configuration = GPT2Config.from_pretrained('/content/gpt2', output_hidden_states=False)\n",
        "\n",
        "# Create the instance of the model and set the token size embedding length\n",
        "model = GPT2LMHeadModel.from_pretrained(\"/content/gpt2\", config=configuration)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()\n",
        "\n",
        "# This step is optional but will enable reproducible runs.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "i8oWfGTSeThK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##set parsebert \n",
        "\n",
        "encoder = BertGenerationEncoder.from_pretrained(\"HooshvareLab/roberta-fa-zwnj-base\", bos_token_id=101, eos_token_id=102)\n",
        "\n",
        "decoder = BertGenerationDecoder.from_pretrained(\n",
        "    \"/content/gpt2\", add_cross_attention=True, is_decoder=True, bos_token_id=101, eos_token_id=102\n",
        ")\n",
        "\n",
        "bert2bert = EncoderDecoderModel(encoder=encoder, decoder=decoder)\n",
        "\n",
        "##set our handy tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\")\n",
        "\n",
        "##a guide on how to use the model\n",
        "loss = bert2bert(input_ids=input_ids, decoder_input_ids=labels, labels=labels).loss\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "0b79hqFmiDvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig, EncoderDecoderConfig, EncoderDecoderModel\n",
        "\n",
        "# Initializing a BERT bert-base-uncased style configuration\n",
        "config_encoder = BertConfig()\n",
        "config_decoder = BertConfig()\n",
        "\n",
        "config = EncoderDecoderConfig.from_encoder_decoder_configs(config_encoder, config_decoder)\n",
        "\n",
        "# Initializing a Bert2Bert model from the bert-base-uncased style configurations\n",
        "model = EncoderDecoderModel(config=config)\n",
        "\n",
        "# Accessing the model configuration\n",
        "config_encoder = model.config.encoder\n",
        "config_decoder = model.config.decoder\n",
        "# set decoder config to causal lm\n",
        "config_decoder.is_decoder = True\n",
        "config_decoder.add_cross_attention = True\n",
        "\n",
        "# Saving the model, including its configuration\n",
        "model.save_pretrained(\"my-model\")\n",
        "\n",
        "# loading model and config from pretrained folder\n",
        "encoder_decoder_config = EncoderDecoderConfig.from_pretrained(\"my-model\")\n",
        "model = EncoderDecoderModel.from_pretrained(\"my-model\", config=encoder_decoder_config)\n",
        "\n",
        "config_encoder = BertConfig(\"HooshvareLab/roberta-fa-zwnj-base\")\n",
        "config_decoder = BertConfig(\"/content/gpt2\")\n",
        "\n",
        "config = EncoderDecoderConfig.from_encoder_decoder_configs(config_encoder, config_decoder)\n",
        "\n",
        "# Initializing a Bert2Bert model from the bert-base-uncased style configurations\n",
        "model = EncoderDecoderModel(config=config)\n",
        "\n",
        "# Accessing the model configuration\n",
        "config_encoder = model.config.encoder\n",
        "config_decoder = model.config.decoder\n",
        "# set decoder config to causal lm\n",
        "config_decoder.is_decoder = True\n",
        "config_decoder.add_cross_attention = True\n",
        "\n",
        "# Saving the model, including its configuration\n",
        "model.save_pretrained(\"my-model\")\n",
        "\n",
        "# loading model and config from pretrained folder\n",
        "encoder_decoder_config = EncoderDecoderConfig.from_pretrained(\"my-model\")\n",
        "model = EncoderDecoderModel.from_pretrained(\"my-model\", config=encoder_decoder_config)"
      ],
      "metadata": {
        "id": "oBaRhxqv3ID9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "warmup_steps = 1e2\n",
        "sample_every = 300"
      ],
      "metadata": {
        "id": "umiQ2kh6fX_l"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "# AdamW is a class from the huggingface library, it is the optimizer we will be using, and we will only be instantiating it with the default parameters.\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=5e-4,\n",
        "    eps=1e-8\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sts5KSlIfiUm",
        "outputId": "d53a7810-0d87-4c1d-c66f-bab97b394809"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\"\"\"\n",
        "Total training steps is the number of data points, times the number of epochs. \n",
        "Essentially, epochs are training cycles, how many times each point will be seen by the model. \n",
        "\"\"\"\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "\"\"\"\n",
        "We can set a variable learning rate which will help scan larger areas of the \n",
        "problem space at higher LR earlier, then fine tune to find the exact model minima \n",
        "at lower LR later in training.\n",
        "\"\"\"\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=total_steps)\n"
      ],
      "metadata": {
        "id": "1V5GrPTHgwJe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(texts[0])[\"input_ids\"]\n",
        "torch.tensor(tokenizer([texts[0]])[\"input_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGf2qvTDg1nJ",
        "outputId": "aaf5f1c9-f792-41a0-9708-b7a90f1268dd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  272,  1486, 13048, 19968,   293,  2251,  4495]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = texts[np.random.randint(0, len(texts))]\n",
        "sample_input = f\"<s>{sample_text}<|startoftext|>\"\n",
        "print(sample_input)\n",
        "sample_input_ids = torch.tensor(tokenizer([sample_input])[\"input_ids\"])\n",
        "sample_input_ids = sample_input_ids.to(device)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    input_ids=sample_input_ids,\n",
        "    # bos_token_id=random.randint(1, len(tokenizer.get_vocab())),\n",
        "    do_sample=True,\n",
        "    top_k=12,\n",
        "    max_length=12,\n",
        "    top_p=0.95,\n",
        "    num_return_sequences=1\n",
        ")\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    gen_sample_output = tokenizer.decode(sample_output, skip_special_tokens=False)\n",
        "    gen_sample_output = gen_sample_output.replace(\"<|startoftext|>\", \"\\n\")\n",
        "    gen_sample_output = gen_sample_output.replace(\"<s>\", \"\")\n",
        "    gen_sample_output = gen_sample_output.replace(\"</s>\", \"\")\n",
        "    gen_sample_output = gen_sample_output.replace(\"<sep>\", \"\\n\")\n",
        "\n",
        "    print(f'Example output: {gen_sample_output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ3-8pQshCjJ",
        "outputId": "635496e1-622f-4ab2-efb7-12ee363c1ef9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>فینال لیگ برتر والیبال نشسته مردان<|startoftext|>\n",
            "Example output: فینال لیگ برتر والیبال نشسته مردان\n",
            "دین و بانوان\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
        "\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in tqdm(range(0, epochs), position=0):\n",
        "\n",
        "    print(f'Beginning epoch {epoch_i + 1} of {epochs}')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader), position=0):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        outputs = model(b_input_ids, labels=b_labels, attention_mask=b_masks, token_type_ids=None)\n",
        "\n",
        "        loss = outputs[0]\n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every 100 batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print()\n",
        "            print(f'Batch {step} of {len(train_dataloader)}. Loss:{batch_loss}. Time:{elapsed}')\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_poet = poets[np.random.randint(0, len(poets))]\n",
        "            sample_input = f\"<s>{sample_poet}<|startoftext|>\"\n",
        "            sample_input_ids = torch.tensor(tokenizer([sample_input])[\"input_ids\"])\n",
        "            sample_input_ids = sample_input_ids.to(device)\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                input_ids=sample_input_ids,\n",
        "                # bos_token_id=random.randint(1, len(tokenizer.get_vocab())),\n",
        "                do_sample=True,\n",
        "                top_k=50,\n",
        "                max_length=50,\n",
        "                top_p=0.95,\n",
        "                num_return_sequences=1\n",
        "            )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                gen_sample_output = tokenizer.decode(sample_output, skip_special_tokens=False)\n",
        "                gen_sample_output = gen_sample_output.replace(\"<|startoftext|>\", \"\\n\")\n",
        "                gen_sample_output = gen_sample_output.replace(\"<s>\", \"\")\n",
        "                gen_sample_output = gen_sample_output.replace(\"</s>\", \"\")\n",
        "                gen_sample_output = gen_sample_output.replace(\"<sep>\", \"\\n\")\n",
        "\n",
        "                print(f'Example output: {gen_sample_output}')\n",
        "\n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print()\n",
        "    print(f'Average Training Loss: {avg_train_loss}. Epoch time: {training_time}')\n",
        "    print()\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in tqdm(validation_dataloader, total=len(validation_dataloader), position=0):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            outputs = model(b_input_ids, attention_mask=b_masks, labels=b_labels)\n",
        "\n",
        "            loss = outputs[0]\n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print()\n",
        "    print(f'Validation loss: {avg_val_loss}. Validation Time: {validation_time}')\n",
        "    print()\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(f'Total training took {format_time(time.time()-total_t0)}')"
      ],
      "metadata": {
        "id": "U9S3Yvvrh8vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITQnDH2JWKAo"
      },
      "outputs": [],
      "source": [
        "TEST_SIZE = 0.15\n",
        "VALIDATION_SIZE = 0.15\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "class CLIPDataset(Dataset):\n",
        "    def __init__(self, list_image_path, list_txt):\n",
        "        self.image_path = list_image_path\n",
        "        self.text = my_tokenizer(list_txt).to(device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = preprocess(Image.open(self.image_path[idx]))\n",
        "        text = self.text[idx]\n",
        "        return image, text\n",
        "\n",
        "# class CLIPDataset(Dataset):\n",
        "#     def __init__(self, images_path, list_txt):\n",
        "#         self.images_path = images_path\n",
        "#         # self.images = list_images.to(device)\n",
        "#         self.text = my_tokenizer(list_txt).to(device)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.text)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         image = images[idx]\n",
        "#         text = self.text[idx]\n",
        "#         return image, text\n",
        "\n",
        "all_df = pd.DataFrame({'text': text_title_list_final, 'image_path': images_list_final})\n",
        "\n",
        "train_df, test_df = train_test_split(all_df, test_size=TEST_SIZE, shuffle=True, random_state=42)\n",
        "train_df, val_df = train_test_split(train_df, test_size=VALIDATION_SIZE, shuffle=True, random_state=42)\n",
        "\n",
        "train_dataset = CLIPDataset(train_df['image_path'].tolist(), train_df['text'].tolist())\n",
        "test_dataset = CLIPDataset(test_df['image_path'].tolist(), test_df['text'].tolist())\n",
        "val_dataset = CLIPDataset(val_df['image_path'].tolist(), val_df['text'].tolist())\n",
        "\n",
        "dataloader = {}\n",
        "dataloader['train'] = DataLoader(train_dataset, batch_size = BATCH_SIZE)\n",
        "dataloader['test'] = DataLoader(test_dataset, batch_size = BATCH_SIZE)\n",
        "dataloader['val'] = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
        "\n",
        "# Show shape of data\n",
        "for phase in ['train', 'test', 'val']:\n",
        "    for item in dataloader[phase]:\n",
        "        print(f'[{phase}]')\n",
        "        print(f'> item[0].shape: ', item[0].shape)\n",
        "        print(f'> item[1].shape: ', item[1].shape)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28M9T4XYWKAo"
      },
      "source": [
        "## Fine-tune model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrCqJ4fMpX11"
      },
      "source": [
        "<div style=\"direction:rtl;\">در این بخش قصد داریم تا مدل ساخته شده را با استفاده از دیتاست مان Fine-tune کنیم.</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOBbl_UHpX11"
      },
      "source": [
        "<div style=\"direction:rtl;\">ابتدا لازم است تا یک سری از هایپرپارامترها را در این بخش تعیین کنیم:</div>\n",
        "</br>\n",
        "\n",
        "| Hyper-paremeter                                         | Value                                               |\n",
        "| ------------------------------------------------------- | --------------------------------------------------- |\n",
        "| Number of Epochs [EPOCH]                                |   10                                                |\n",
        "| Learning-Rate [LR]                                      |   1e-7                                              |\n",
        "| Eps for Adam-optimizer [EPS]                            |   1e-9                                              |\n",
        "| Weight decay of Adam-optimizer [WEIGHT_DECAY]           |   0.1                                               |\n",
        "| Maximum of learning-rate value for scheduler [MAX_LR]   |   1e-2                                              |\n",
        "| Optimizer                                               |   Adam                                              |\n",
        "| Learning-rate scheduler [scheduler]                     |   OneCycleLR                                        |\n",
        "| Image and text prediction loss                          |   CrossEntropyLoss                                  |\n",
        "| Number of freeze layers                                 |   20 layer of each module (visual and transformer)  |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE-R41RezF8H"
      },
      "outputs": [],
      "source": [
        "# !mkdir /content/drive/MyDrive/clip_trained_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32H5ab1nl_QZ"
      },
      "outputs": [],
      "source": [
        "EPOCH = 10\n",
        "LR = 1e-3\n",
        "EPS = 1e-9\n",
        "WEIGHT_DECAY = 0.1\n",
        "MAX_LR = 5e-3\n",
        "MIN_LR = 1e-7\n",
        "BASE_MODEL_PATH = '/content/drive/MyDrive/TasnimDataset/models/clip_trained_model/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-La7qSMVWIZ"
      },
      "outputs": [],
      "source": [
        "loss_img = nn.CrossEntropyLoss()\n",
        "loss_txt = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), \n",
        "                             lr=LR,\n",
        "                             betas=(0.9,0.98),\n",
        "                             eps=EPS,\n",
        "                             weight_decay=WEIGHT_DECAY) \n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
        "                                                max_lr=MAX_LR, \n",
        "                                                steps_per_epoch=len(dataloader['train']), \n",
        "                                                epochs=EPOCH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gkQhih_ebp1"
      },
      "source": [
        "<div style=\"direction:rtl;\">در این بخش مدل زبانی و مدل تصویر ۲۰ لایه آخر به حالت قابل آموزش هستند و بقیه مدل فریز شده است:</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1HXx-XHpX12"
      },
      "outputs": [],
      "source": [
        "layer_num = [0, 0]\n",
        "freeze_layer_thr = 30\n",
        "freeze_layer_txt_thr = 20\n",
        "\n",
        "for param in model.transformer.parameters():\n",
        "    layer_num[0]+=1\n",
        "for param in model.visual.parameters():\n",
        "    layer_num[1]+=1\n",
        "\n",
        "for i, param in enumerate(model.transformer.parameters()):\n",
        "    if freeze_layer_txt_thr >= layer_num[0] - i:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "for i, param in enumerate(model.visual.parameters()):\n",
        "    if freeze_layer_thr >= layer_num[1] - i:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZF7V8dlpX12"
      },
      "source": [
        "<div style=\"direction:rtl;\">فرآیند آموزش به این شکل است که دارای دو فاز آموزش و اعتبار می باشد، در فاز آموزش گرادیان ها حساب شده و مراحل backpropagation انجام می شود ولی در فاز اعتبار صرفا بررسی می شود که مقدار loss چقدر است برای این داده ها، به نوعی برای مشخص کردن محلی است که مدل به اندازه کافی خوب شده است. که در این آموزش در ایپاک ۴ مدل خوب شده است.</div>\n",
        "\n",
        "</br>\n",
        "\n",
        "<div style=\"direction:rtl;\">به منظور محاسبه loss در هنگام یادگیری، مطابق با <a href=\"https://arxiv.org/abs/2103.00020\">مقاله CLIP</a> فرآیند انجام شده است:</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "<p align=\"center\"><img src=\"https://github.com/AAhmadS/NLP-HW3/blob/data/clip_train_loss.png?raw=1\" width=60% /></p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHNzRPPOWKAp"
      },
      "outputs": [],
      "source": [
        "def train_model(model, optimizer, scheduler, num_epochs=10):\n",
        "    since = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        best_val_loss = 10000000 \n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            total_loss = 0.0\n",
        "            num = 0\n",
        "\n",
        "            with tqdm(dataloader[phase]) as pbar:\n",
        "              for batch in pbar:\n",
        "                optimizer.zero_grad()\n",
        "                images, texts = batch\n",
        "                images = images.to(device)\n",
        "                texts = texts.to(device)\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    logits_per_image, logits_per_text = model(images, texts)\n",
        "                    ground_truth = torch.arange(len(images),dtype=torch.long,device=device)\n",
        "                    batch_loss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        batch_loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                total_loss += batch_loss\n",
        "                num += 1\n",
        "              if phase == 'train':\n",
        "                  scheduler.step()\n",
        "\n",
        "              epoch_loss = total_loss / num\n",
        "              pbar.set_description(f'EPOCH:{epoch+1} - Loss: {epoch_loss/(i+1):.4f}')    \n",
        "\n",
        "              \n",
        "              if phase == 'val':\n",
        "                if epoch_loss < best_val_loss:\n",
        "                  best_val_loss = epoch_loss\n",
        "                  torch.save(model.state_dict(), BASE_MODEL_PATH+f'clip_en_fi_ep.pt')\n",
        "\n",
        "              print(f'{phase} Loss: {epoch_loss:.4f}')\n",
        "\n",
        "              if phase == 'train':\n",
        "                  torch.save(model.state_dict(), BASE_MODEL_PATH+f'clip_en_fi_ep{epoch}.pt')\n",
        "        print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XQlseyeskc3",
        "outputId": "b36f38c3-a1a7-4312-be79-10539992843a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/467 [00:17<1:08:41,  8.86s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-451e4ab274b9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-307d6c366f92>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_model(model=model, optimizer=optimizer, scheduler=scheduler, num_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.save(model.state_dict(), f'clip_en_fi_ep{1}.pt')\n",
        "          "
      ],
      "metadata": {
        "id": "Bd7-XnKhYbkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adding the decoder to the model"
      ],
      "metadata": {
        "id": "oqERFn9YJ6YV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q BertGeneration"
      ],
      "metadata": {
        "id": "FmcexjWGMCXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import BertGeneration\n",
        "decoder = BertGenerationDecoder.from_pretrained(\n",
        "    \"bert-large-uncased\", add_cross_attention=True, is_decoder=True, bos_token_id=101, eos_token_id=102\n",
        ")"
      ],
      "metadata": {
        "id": "hRUx1Hm5J8Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##decoding loop\n",
        "\n",
        "def train_model(model, optimizer, scheduler, num_epochs=5, criterion):\n",
        "    since = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        best_val_loss = 10000000 \n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            total_loss = 0.0\n",
        "            num = 0\n",
        "\n",
        "            for batch in tqdm(dataloader[phase]):\n",
        "                optimizer.zero_grad()\n",
        "                images, texts = batch\n",
        "                images = images.to(device)\n",
        "                texts = texts.to(device)\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    logits = model(images)\n",
        "                    ground_truth = texts\n",
        "                    batch_loss = criterion(logits, ground_truth)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        batch_loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                total_loss += batch_loss\n",
        "                num += 1\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = total_loss / num\n",
        "            \n",
        "            if phase == 'val':\n",
        "              if epoch_loss < best_val_loss:\n",
        "                best_val_loss = epoch_loss\n",
        "                torch.save(model.state_dict(), BASE_MODEL_PATH+f'clip_en_fi_ep_dec.pt')\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f}')\n",
        "\n",
        "            if phase == 'train':\n",
        "                torch.save(model.state_dict(), BASE_MODEL_PATH+f'clip_en_fi_ep_dec{epoch}.pt')\n",
        "            \n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')"
      ],
      "metadata": {
        "id": "uT98v5aRJ-rK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##suitable dataset based on latent vectors extracted from data\n",
        "\n",
        "##todo \n",
        "\n",
        "##give all data latent vectors and save in the drive\n",
        "\n",
        "\n",
        "## create the dataset, it should take vectors and text as input and output"
      ],
      "metadata": {
        "id": "o-YunH6AKBif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## parameters "
      ],
      "metadata": {
        "id": "8sI9zeEvKDfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##run"
      ],
      "metadata": {
        "id": "P4ydHMNYKa3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import Dataset  # this is the pytorch class import\n",
        "# import torch\n",
        "# torch.manual_seed(42)\n",
        "\n",
        "\n",
        "# class MTGDataset(Dataset):\n",
        "\n",
        "#     def __init__(self, txt_list, tokenizer, max_length=1024):\n",
        "\n",
        "#         self.tokenizer = tokenizer  # the gpt2 tokenizer we instantiated\n",
        "#         self.input_ids = []\n",
        "#         self.attn_masks = []\n",
        "\n",
        "#         for txt in txt_list:\n",
        "#             \"\"\"\n",
        "#             This loop will iterate through each entry in the flavour text corpus.\n",
        "#             For each bit of text it will prepend it with the start of text token,\n",
        "#             then append the end of text token and pad to the maximum length with the \n",
        "#             pad token. \n",
        "#             \"\"\"\n",
        "\n",
        "#             encodings_dict = tokenizer('<s>' + txt + '</s>',\n",
        "#                                        truncation=True,\n",
        "#                                        max_length=max_length,\n",
        "#                                        padding=\"max_length\")\n",
        "\n",
        "#             \"\"\"\n",
        "#             Each iteration then appends either the encoded tensor to a list,\n",
        "#             or the attention mask for that encoding to a list. The attention mask is\n",
        "#             a binary list of 1's or 0's which determine whether the langauge model\n",
        "#             should take that token into consideration or not. \n",
        "#             \"\"\"\n",
        "#             self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "#             self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.input_ids)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.input_ids[idx], self.attn_masks[idx]"
      ],
      "metadata": {
        "id": "gfldvKZyc8hK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import random_split\n",
        "\n",
        "# texts = list(set(text_title_list_final))\n",
        "\n",
        "# dataset = MTGDataset(texts, tokenizer, max_length=max_seq)\n",
        "\n",
        "# # Split into training and validation sets\n",
        "# train_size = int(0.95 * len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# f'There are {len(train_dataset)} samples for training, and {len(val_dataset)} samples for validation testing'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9nbrD34fdFm_",
        "outputId": "6088cb96-d216-48bc-b1ea-1412d9669fd5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are 1313 samples for training, and 70 samples for validation testing'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# train_dataloader = DataLoader(\n",
        "#     train_dataset,\n",
        "#     sampler=RandomSampler(train_dataset),\n",
        "#     batch_size=8\n",
        "# )\n",
        "\n",
        "# validation_dataloader = DataLoader(\n",
        "#     val_dataset,\n",
        "#     sampler=SequentialSampler(val_dataset),\n",
        "#     batch_size=8\n",
        "# )"
      ],
      "metadata": {
        "id": "h8xPqPzPeHTS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUM8HYQPeh4o",
        "outputId": "0a2aa11a-4095-4a2f-e3fb-f797a9ebe123"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42001"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}