{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "27c55e1e33aa413193c1413ac9c1436e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9624fbf81744042aeb454a21aa070fd",
              "IPY_MODEL_e597227d4c4f4221aa8d7f79029f5137",
              "IPY_MODEL_edeb0f16d1a34c1bbe37d6691f2ad7d7"
            ],
            "layout": "IPY_MODEL_4321532081964ee9b4429918860ed73d"
          }
        },
        "a9624fbf81744042aeb454a21aa070fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa73f99158614a809e2efd8dc8e2f742",
            "placeholder": "​",
            "style": "IPY_MODEL_a87cdad4fa8f4822869730350de44d36",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "e597227d4c4f4221aa8d7f79029f5137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01190ae08d0e47e58fffc038874c9bfb",
            "max": 1441,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef2552a71e5e4948b2fee286cfe413cd",
            "value": 1441
          }
        },
        "edeb0f16d1a34c1bbe37d6691f2ad7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27b525952558401e90d27e0659c9160a",
            "placeholder": "​",
            "style": "IPY_MODEL_61e5b6d5577d4e6eb6af6d029d91e938",
            "value": " 1.44k/1.44k [00:00&lt;00:00, 59.8kB/s]"
          }
        },
        "4321532081964ee9b4429918860ed73d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa73f99158614a809e2efd8dc8e2f742": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a87cdad4fa8f4822869730350de44d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01190ae08d0e47e58fffc038874c9bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef2552a71e5e4948b2fee286cfe413cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27b525952558401e90d27e0659c9160a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61e5b6d5577d4e6eb6af6d029d91e938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d120e90178c400299754abacfd14509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8961502258c84bddacf4bfe805621d7a",
              "IPY_MODEL_f52bf16ab5e343ccb9acfe15628a8d09",
              "IPY_MODEL_1f09e6c418cf451383c55488e90ae3d1"
            ],
            "layout": "IPY_MODEL_78f6e04765fb418bbc75d60a55fa503e"
          }
        },
        "8961502258c84bddacf4bfe805621d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_651ca6fb79e44b82b654252e988a5854",
            "placeholder": "​",
            "style": "IPY_MODEL_1b1c7c4321b945d397e90e23942dff85",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "f52bf16ab5e343ccb9acfe15628a8d09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34ffacbf1fce4f458936228f94203101",
            "max": 62,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cb312530df34408be5fcb2a6c16fb51",
            "value": 62
          }
        },
        "1f09e6c418cf451383c55488e90ae3d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9db52b0e959241699ea22d913eca5a75",
            "placeholder": "​",
            "style": "IPY_MODEL_6dc74283cdf145f1a10bdc6bcdab25ba",
            "value": " 62.0/62.0 [00:00&lt;00:00, 2.57kB/s]"
          }
        },
        "78f6e04765fb418bbc75d60a55fa503e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "651ca6fb79e44b82b654252e988a5854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b1c7c4321b945d397e90e23942dff85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34ffacbf1fce4f458936228f94203101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cb312530df34408be5fcb2a6c16fb51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9db52b0e959241699ea22d913eca5a75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dc74283cdf145f1a10bdc6bcdab25ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8995ea372c344ce995f0cf635644e98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fc1a99ac1774e12a4552f9245657a68",
              "IPY_MODEL_99f61deb7cbb4638817dcdd7439bb845",
              "IPY_MODEL_0e35c06cf7c94db2b104b1fdb40bf058"
            ],
            "layout": "IPY_MODEL_7f99220730fc49e09aa7128267e54a3f"
          }
        },
        "8fc1a99ac1774e12a4552f9245657a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b29a9cf98409419fb337ac3adf68d11e",
            "placeholder": "​",
            "style": "IPY_MODEL_6c13b01765b04eb39b2d7b654f3dbcac",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "99f61deb7cbb4638817dcdd7439bb845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdad420d5b3a4f5ca2161fd750243d80",
            "max": 1198122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7478c5c3dddb4f7fb6a2b0298b992be7",
            "value": 1198122
          }
        },
        "0e35c06cf7c94db2b104b1fdb40bf058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc4090e481294eeca92c54f7d6fd3b3c",
            "placeholder": "​",
            "style": "IPY_MODEL_f92451780c8146d08187959f844e89be",
            "value": " 1.20M/1.20M [00:00&lt;00:00, 4.65MB/s]"
          }
        },
        "7f99220730fc49e09aa7128267e54a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b29a9cf98409419fb337ac3adf68d11e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c13b01765b04eb39b2d7b654f3dbcac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdad420d5b3a4f5ca2161fd750243d80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7478c5c3dddb4f7fb6a2b0298b992be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc4090e481294eeca92c54f7d6fd3b3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f92451780c8146d08187959f844e89be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0b5051082524b67b56089cd31eda9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69b4299cbf4f40c683544bbb75be3781",
              "IPY_MODEL_81dd4cfedb5f49cca382bf689077cda2",
              "IPY_MODEL_02e4dcccf47b47ca82aa830d91f73aaf"
            ],
            "layout": "IPY_MODEL_67cfdc06e8de4205aec730d1a534e316"
          }
        },
        "69b4299cbf4f40c683544bbb75be3781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7830ac8c291e40d2a50aed280bbbe014",
            "placeholder": "​",
            "style": "IPY_MODEL_2569891c2fbf4bdc814baa4c3b3a0ff0",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "81dd4cfedb5f49cca382bf689077cda2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_911c610cf8004bdbac2fe2641f53def6",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b504f5be76bd4085af04303853752397",
            "value": 112
          }
        },
        "02e4dcccf47b47ca82aa830d91f73aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfc9b8f9e1324a07a65b5429dd41fc10",
            "placeholder": "​",
            "style": "IPY_MODEL_cc4f4e0fcb984234883fa11e6adf185d",
            "value": " 112/112 [00:00&lt;00:00, 3.53kB/s]"
          }
        },
        "67cfdc06e8de4205aec730d1a534e316": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7830ac8c291e40d2a50aed280bbbe014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2569891c2fbf4bdc814baa4c3b3a0ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "911c610cf8004bdbac2fe2641f53def6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b504f5be76bd4085af04303853752397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfc9b8f9e1324a07a65b5429dd41fc10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc4f4e0fcb984234883fa11e6adf185d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fea784b9a3c4863bde2e341ce452340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6b69411594b40f2bd34bdb59f5184c3",
              "IPY_MODEL_d4d2b937196d4b46847226807528b221",
              "IPY_MODEL_0e23a8f767274fcfb36874d99cb58d8f"
            ],
            "layout": "IPY_MODEL_4c8ff23a5e0f461fb6d121fa459ebdba"
          }
        },
        "d6b69411594b40f2bd34bdb59f5184c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_586ddd25c4af4f5fa62ac47d3f43e0ca",
            "placeholder": "​",
            "style": "IPY_MODEL_7d128b0d91d04e33b1cdcfeb97e30ac0",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "d4d2b937196d4b46847226807528b221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ab6c282add54a419a022f769d12b16f",
            "max": 651477729,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbb61982df5c4563aa44cf5b1c1ab4f0",
            "value": 651477729
          }
        },
        "0e23a8f767274fcfb36874d99cb58d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0732ab6c49f4a3d924b38cdfd033ba9",
            "placeholder": "​",
            "style": "IPY_MODEL_4f9aed92c0bc4502a6dddf1b629d1244",
            "value": " 651M/651M [00:04&lt;00:00, 178MB/s]"
          }
        },
        "4c8ff23a5e0f461fb6d121fa459ebdba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "586ddd25c4af4f5fa62ac47d3f43e0ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d128b0d91d04e33b1cdcfeb97e30ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ab6c282add54a419a022f769d12b16f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbb61982df5c4563aa44cf5b1c1ab4f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0732ab6c49f4a3d924b38cdfd033ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f9aed92c0bc4502a6dddf1b629d1244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AAhmadS/NLP-HW3/blob/main/Copy_of_Copy_of_Copy_of_NLP_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycCs7DfEpX1u"
      },
      "source": [
        "## Install and import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jtkeu_Wx0ai",
        "outputId": "a27dae08-e2f6-4787-f990-fe040cd71cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/TasnimDataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DCVttnZJ5OG",
        "outputId": "4adba0ef-7cc7-43ff-8301-61dc2152452f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/TasnimDataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BpdJkdBssk9",
        "outputId": "4426c3e1-36a3-4d8e-9450-837c42d01651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.6)\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-g1ouszi8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-g1ouszi8\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a9b1bf5920416aaeaec965c25dd9e8f98c864f16\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.65.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.15.2+cu118)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->clip==1.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->clip==1.0) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369370 sha256=a55bf6031e9fb6c8b56740aabdd9ce562897e5c179e71bc3c591958bb267d967\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u71g2dwa/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "Successfully installed clip-1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 tokenizers-0.13.3 transformers-4.29.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting arabic-reshaper\n",
            "  Downloading arabic_reshaper-3.0.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: arabic-reshaper\n",
            "Successfully installed arabic-reshaper-3.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-bidi\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi) (1.16.0)\n",
            "Installing collected packages: python-bidi\n",
            "Successfully installed python-bidi-0.4.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dadmatools\n",
            "  Downloading dadmatools-1.5.2-py3-none-any.whl (862 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.6/862.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bpemb>=0.3.3 (from dadmatools)\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from dadmatools) (3.8.1)\n",
            "Requirement already satisfied: folium>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from dadmatools) (0.14.0)\n",
            "Requirement already satisfied: spacy>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dadmatools) (3.5.2)\n",
            "Collecting sklearn>=0.0 (from dadmatools)\n",
            "  Downloading sklearn-0.0.post5.tar.gz (3.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from dadmatools) (2.0.1+cu118)\n",
            "Requirement already satisfied: transformers>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from dadmatools) (4.29.2)\n",
            "Requirement already satisfied: h5py>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dadmatools) (3.8.0)\n",
            "Collecting Deprecated==1.2.6 (from dadmatools)\n",
            "  Downloading Deprecated-1.2.6-py2.py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: hyperopt>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from dadmatools) (0.2.7)\n",
            "Collecting pyconll>=3.1.0 (from dadmatools)\n",
            "  Downloading pyconll-3.1.0-py3-none-any.whl (26 kB)\n",
            "Collecting pytorch-transformers>=1.1.0 (from dadmatools)\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting segtok>=1.5.7 (from dadmatools)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.6 in /usr/local/lib/python3.10/dist-packages (from dadmatools) (0.8.10)\n",
            "Collecting supar==1.1.2 (from dadmatools)\n",
            "  Downloading supar-1.1.2-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gensim>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from dadmatools) (4.3.1)\n",
            "Collecting conllu (from dadmatools)\n",
            "  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: gdown>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from dadmatools) (4.6.6)\n",
            "Collecting NERDA (from dadmatools)\n",
            "  Downloading NERDA-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting py7zr>=0.17.2 (from dadmatools)\n",
            "  Downloading py7zr-0.20.5-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting html2text (from dadmatools)\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109 (from dadmatools)\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated==1.2.6->dadmatools) (1.14.1)\n",
            "Collecting stanza (from supar==1.1.2->dadmatools)\n",
            "  Downloading stanza-1.5.0-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.5/802.5 kB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from supar==1.1.2->dadmatools)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.3->dadmatools) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.3->dadmatools) (2.27.1)\n",
            "Collecting sentencepiece (from bpemb>=0.3.3->dadmatools)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.3->dadmatools) (4.65.0)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from folium>=0.2.1->dadmatools) (0.6.0)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from folium>=0.2.1->dadmatools) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.3.1->dadmatools) (3.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.3.1->dadmatools) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.3.1->dadmatools) (4.11.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.6.0->dadmatools) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.6.0->dadmatools) (6.3.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.5->dadmatools) (3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.5->dadmatools) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.5->dadmatools) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.5->dadmatools) (0.10.9.7)\n",
            "Collecting texttable (from py7zr>=0.17.2->dadmatools)\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pycryptodomex>=3.6.6 (from py7zr>=0.17.2->dadmatools)\n",
            "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd>=0.14.4 (from py7zr>=0.17.2->dadmatools)\n",
            "  Downloading pyzstd-0.15.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (399 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.3/399.3 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1 (from py7zr>=0.17.2->dadmatools)\n",
            "  Downloading pyppmd-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj>=0.6.0 (from py7zr>=0.17.2->dadmatools)\n",
            "  Downloading pybcj-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr>=0.17.2->dadmatools)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting brotli>=1.0.9 (from py7zr>=0.17.2->dadmatools)\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflate64>=0.3.1 (from py7zr>=0.17.2->dadmatools)\n",
            "  Downloading inflate64-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr>=0.17.2->dadmatools) (5.9.5)\n",
            "Collecting boto3 (from pytorch-transformers>=1.1.0->dadmatools)\n",
            "  Downloading boto3-1.26.146-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers>=1.1.0->dadmatools) (2022.10.31)\n",
            "Collecting sacremoses (from pytorch-transformers>=1.1.0->dadmatools)\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.0->dadmatools) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.0->dadmatools) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.0->dadmatools) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.0->dadmatools) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.0->dadmatools) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.0->dadmatools) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.0->dadmatools) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.0->dadmatools) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.0->dadmatools) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.0->dadmatools) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.0->dadmatools) (0.10.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.0->dadmatools) (1.10.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.0->dadmatools) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.0->dadmatools) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.0->dadmatools) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->dadmatools) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->dadmatools) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->dadmatools) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.1->dadmatools) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.1->dadmatools) (16.0.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.9.1->dadmatools) (0.15.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.9.1->dadmatools) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.9.1->dadmatools) (0.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from NERDA->dadmatools) (1.5.3)\n",
            "Collecting progressbar (from NERDA->dadmatools)\n",
            "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->dadmatools) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->dadmatools) (1.2.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.9.1->dadmatools) (2023.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9->folium>=0.2.1->dadmatools) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.0.0->dadmatools) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.0.0->dadmatools) (0.0.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.3.1->dadmatools) (2.4.1)\n",
            "Collecting botocore<1.30.0,>=1.29.146 (from boto3->pytorch-transformers>=1.1.0->dadmatools)\n",
            "  Downloading botocore-1.29.146-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch-transformers>=1.1.0->dadmatools)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->pytorch-transformers>=1.1.0->dadmatools)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->NERDA->dadmatools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->NERDA->dadmatools) (2022.7.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (1.7.1)\n",
            "Collecting emoji (from stanza->supar==1.1.2->dadmatools)\n",
            "  Downloading emoji-2.4.0.tar.gz (353 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.7/353.7 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanza->supar==1.1.2->dadmatools) (3.20.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.1->dadmatools) (1.3.0)\n",
            "Building wheels for collected packages: sklearn, progressbar, sacremoses, emoji\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post5-py3-none-any.whl size=2950 sha256=b12d05efb8e724aee5c8bfbc9f03f60086aae57361ddc15b751528f1a03945c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/1f/8d/4f812c590e074c1e928f5cec67bf5053b71f38e2648739403a\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12067 sha256=a4aeb7043bce10b9212b68077dc281aa204eaa14650e2121b4db64f7c03d2f31\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/17/e5/765d1a3112ff3978f70223502f6047e06c43a24d7c5f8ff95b\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=4b5d5e20b226eb4f046bc0e51860116a20c90bc7b4b36d7589f92a8b437778b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.4.0-py2.py3-none-any.whl size=350809 sha256=213f3dd1b89fd42261c8324794e5ce5dc1074a6b383006ce3f73d73156757894\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/29/1c/234cae4632803c2ba4a76a71a679eb1383cf590775714e2a21\n",
            "Successfully built sklearn progressbar sacremoses emoji\n",
            "Installing collected packages: tf-estimator-nightly, texttable, sklearn, sentencepiece, progressbar, brotli, segtok, sacremoses, pyzstd, pyppmd, pycryptodomex, pyconll, pybcj, multivolumefile, jmespath, inflate64, html2text, emoji, dill, Deprecated, conllu, py7zr, botocore, s3transfer, bpemb, boto3, stanza, supar, pytorch-transformers, NERDA, dadmatools\n",
            "Successfully installed Deprecated-1.2.6 NERDA-1.0.0 boto3-1.26.146 botocore-1.29.146 bpemb-0.3.4 brotli-1.0.9 conllu-4.5.2 dadmatools-1.5.2 dill-0.3.6 emoji-2.4.0 html2text-2020.1.16 inflate64-0.3.1 jmespath-1.0.1 multivolumefile-0.2.3 progressbar-2.5 py7zr-0.20.5 pybcj-1.0.1 pyconll-3.1.0 pycryptodomex-3.18.0 pyppmd-1.0.0 pytorch-transformers-1.2.0 pyzstd-0.15.7 s3transfer-0.6.1 sacremoses-0.0.53 segtok-1.5.11 sentencepiece-0.1.99 sklearn-0.0.post5 stanza-1.5.0 supar-1.1.2 texttable-1.6.7 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ],
      "source": [
        "! pip install ftfy regex tqdm\n",
        "! pip install git+https://github.com/openai/CLIP.git\n",
        "! pip install transformers\n",
        "! pip install arabic-reshaper\n",
        "! pip install python-bidi\n",
        "# ! pip install hazm\n",
        "! pip install dadmatools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jVd-ynYaWwea"
      },
      "outputs": [],
      "source": [
        "# ! mkdir fonts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1hkDT38hSaP",
        "outputId": "78764a36-ccd2-4e71-b682-5a6dc78357f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 2.0.1+cu118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-67df6789a0a0>:36: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
            "  from scipy.ndimage.filters import gaussian_filter\n"
          ]
        }
      ],
      "source": [
        "from __future__ import unicode_literals\n",
        "# from hazm import Normalizer as hNormalizer\n",
        "# from dadmatools.models.normalizer import Normalizer as dNormalizer\n",
        "import gc\n",
        "import time\n",
        "import copy\n",
        "import PIL\n",
        "import torch\n",
        "import os\n",
        "# import dill\n",
        "import clip\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import multiprocessing\n",
        "from tqdm import tqdm\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "from pkg_resources import packaging\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from matplotlib.font_manager import FontProperties\n",
        "from bidi.algorithm import get_display\n",
        "from arabic_reshaper import reshape\n",
        "from torch.cuda.amp import autocast\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import CLIPModel, CLIPConfig, CLIPVisionModel, CLIPFeatureExtractor\n",
        "from transformers import AutoModel, AutoTokenizer, AutoModel, TFAutoModel, AutoConfig\n",
        "from transformers import BertModel\n",
        "from transformers import TrainingArguments, Trainer, RobertaModel\n",
        "from transformers import default_data_collator\n",
        "from IPython.display import clear_output\n",
        "import seaborn as sns\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "\n",
        "# persian_font = FontProperties(fname='/content/fonts/Vazirmatn-Regular.ttf')\n",
        "# \n",
        "print(\"Torch version:\", torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQT2E9PoWKAn"
      },
      "source": [
        "## Defining the ML-Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2quvXE5pX1z"
      },
      "source": [
        "<div style=\"direction:rtl;\">در ادامه قصد داریم با استفاده از Fine-tune کردن مدل <a href=\"https://github.com/openai/CLIP\">CLIP</a> به یک مدل مناسب برای ترکیب متن و تصویر دست پیدا کنیم:</div> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c58ycUu6Nd2C"
      },
      "source": [
        "#### Loading CLIP model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85O8r4TepX10"
      },
      "source": [
        "<div style=\"direction:rtl;\">بررسی مدل های قابل استفاده در CLIP:</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOKzv2bCWKAo",
        "outputId": "fb0897cd-3bbc-45a0-c38f-3fa4993f39c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RN50',\n",
              " 'RN101',\n",
              " 'RN50x4',\n",
              " 'RN50x16',\n",
              " 'RN50x64',\n",
              " 'ViT-B/32',\n",
              " 'ViT-B/16',\n",
              " 'ViT-L/14',\n",
              " 'ViT-L/14@336px']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "clip.available_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ7TtWVKpX10"
      },
      "source": [
        "<div style=\"direction:rtl;\">تعیین استفاده از GPU درصورت وجود:</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "l79DaXF9WKAo",
        "outputId": "d914a3bd-58e8-48f7-e1b6-b970f091638c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTwyhMwnpX10"
      },
      "source": [
        "<div style=\"direction:rtl;\">در این بخش مدل CLIP(ViT-L/14) لود شده است و تمامی متغیرهای آن به حالت float32 در آمده است (چون بعضی از متغییر های متبنی بر float16 بودند و به دلیل این که در ادامه قسمت مدل زبانی این مدل تغییر داده شده است، امکان همخوانی با بقیه بخش ها را نداشت.)</div>\n",
        "\n",
        "</br>\n",
        "\n",
        "<div style=\"direction:rtl;\">همچنین از مدل زبان فارسی BERT <a href=\"https://github.com/hooshvare/parsbert\">ParsBERT</a> نیز استفاده شده است.</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "27c55e1e33aa413193c1413ac9c1436e",
            "a9624fbf81744042aeb454a21aa070fd",
            "e597227d4c4f4221aa8d7f79029f5137",
            "edeb0f16d1a34c1bbe37d6691f2ad7d7",
            "4321532081964ee9b4429918860ed73d",
            "aa73f99158614a809e2efd8dc8e2f742",
            "a87cdad4fa8f4822869730350de44d36",
            "01190ae08d0e47e58fffc038874c9bfb",
            "ef2552a71e5e4948b2fee286cfe413cd",
            "27b525952558401e90d27e0659c9160a",
            "61e5b6d5577d4e6eb6af6d029d91e938",
            "3d120e90178c400299754abacfd14509",
            "8961502258c84bddacf4bfe805621d7a",
            "f52bf16ab5e343ccb9acfe15628a8d09",
            "1f09e6c418cf451383c55488e90ae3d1",
            "78f6e04765fb418bbc75d60a55fa503e",
            "651ca6fb79e44b82b654252e988a5854",
            "1b1c7c4321b945d397e90e23942dff85",
            "34ffacbf1fce4f458936228f94203101",
            "4cb312530df34408be5fcb2a6c16fb51",
            "9db52b0e959241699ea22d913eca5a75",
            "6dc74283cdf145f1a10bdc6bcdab25ba",
            "8995ea372c344ce995f0cf635644e98b",
            "8fc1a99ac1774e12a4552f9245657a68",
            "99f61deb7cbb4638817dcdd7439bb845",
            "0e35c06cf7c94db2b104b1fdb40bf058",
            "7f99220730fc49e09aa7128267e54a3f",
            "b29a9cf98409419fb337ac3adf68d11e",
            "6c13b01765b04eb39b2d7b654f3dbcac",
            "bdad420d5b3a4f5ca2161fd750243d80",
            "7478c5c3dddb4f7fb6a2b0298b992be7",
            "fc4090e481294eeca92c54f7d6fd3b3c",
            "f92451780c8146d08187959f844e89be",
            "b0b5051082524b67b56089cd31eda9fa",
            "69b4299cbf4f40c683544bbb75be3781",
            "81dd4cfedb5f49cca382bf689077cda2",
            "02e4dcccf47b47ca82aa830d91f73aaf",
            "67cfdc06e8de4205aec730d1a534e316",
            "7830ac8c291e40d2a50aed280bbbe014",
            "2569891c2fbf4bdc814baa4c3b3a0ff0",
            "911c610cf8004bdbac2fe2641f53def6",
            "b504f5be76bd4085af04303853752397",
            "bfc9b8f9e1324a07a65b5429dd41fc10",
            "cc4f4e0fcb984234883fa11e6adf185d",
            "6fea784b9a3c4863bde2e341ce452340",
            "d6b69411594b40f2bd34bdb59f5184c3",
            "d4d2b937196d4b46847226807528b221",
            "0e23a8f767274fcfb36874d99cb58d8f",
            "4c8ff23a5e0f461fb6d121fa459ebdba",
            "586ddd25c4af4f5fa62ac47d3f43e0ca",
            "7d128b0d91d04e33b1cdcfeb97e30ac0",
            "7ab6c282add54a419a022f769d12b16f",
            "dbb61982df5c4563aa44cf5b1c1ab4f0",
            "f0732ab6c49f4a3d924b38cdfd033ba9",
            "4f9aed92c0bc4502a6dddf1b629d1244"
          ]
        },
        "id": "7xcdNKjEZ7eN",
        "outputId": "aa6a5c43-b2dc-4cbb-b132-af6df9ac6c71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 891M/891M [00:35<00:00, 26.2MiB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27c55e1e33aa413193c1413ac9c1436e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d120e90178c400299754abacfd14509"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.20M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8995ea372c344ce995f0cf635644e98b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0b5051082524b67b56089cd31eda9fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/651M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fea784b9a3c4863bde2e341ce452340"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased-clf-persiannews were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device, jit=False)\n",
        "model = model.float()\n",
        "parsbert_path = \"HooshvareLab/bert-fa-base-uncased-clf-persiannews\"\n",
        "config = AutoConfig.from_pretrained(parsbert_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(parsbert_path)\n",
        "parsbert = BertModel.from_pretrained(parsbert_path).float().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "550KqfU6NfDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed300b04-f24a-4068-abf7-898a548561c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CLIP(\n",
              "  (visual): VisionTransformer(\n",
              "    (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
              "    (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (transformer): Transformer(\n",
              "      (resblocks): Sequential(\n",
              "        (0): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (12): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (13): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (14): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (15): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (16): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (17): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (18): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (19): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (20): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (21): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (22): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (23): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (transformer): Transformer(\n",
              "    (resblocks): Sequential(\n",
              "      (0): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (1): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (2): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (3): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (4): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (5): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (6): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (7): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (8): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (9): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (10): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (11): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (token_embedding): Embedding(49408, 768)\n",
              "  (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parsbert"
      ],
      "metadata": {
        "id": "z9TPosRENhPo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ete0nQRLMl1J"
      },
      "source": [
        "#### Replaceing the text-encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNjeBzfQpX10"
      },
      "source": [
        "<div style=\"direction:rtl;\">در این بخش در تابع <code>my_encode_text</code> تعریف شده است که از مدل ParsBERT برای بخش زبانی مدل استفاده شود و همچنین در تابع <code>my_tokenizer</code> تعریف شده است که توکنایزر اولیه، متن را به چه شکل توکن کند که این توکنایزر نیز توکنایزر ParsBERT می باشد که به خوبی زبان فارسی را تشخیص می دهد.</div>\n",
        "\n",
        "</br>\n",
        "\n",
        "<div style=\"direction:rtl;\">در نهایت تابع کدکننده متن را به عنوان انکدر مدل اصلی جایگزین می کنیم و همچنین به عنوان معماری ترنسفورمر نیز مدر ParsBERT را جایگزین می کنیم.</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "s2FK5sqMaUUV"
      },
      "outputs": [],
      "source": [
        "def my_encode_text(text):\n",
        "    return parsbert(text).pooler_output\n",
        "\n",
        "def my_tokenizer(texts):\n",
        "    out_encode = []\n",
        "    for t in texts:\n",
        "        out_encode.append(tokenizer.encode_plus(\n",
        "                t,\n",
        "                max_length=10,\n",
        "                truncation=True,\n",
        "                add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "                return_token_type_ids=True,\n",
        "                return_attention_mask=True,\n",
        "                padding='max_length',\n",
        "                return_tensors='pt',  # Return PyTorch tensors\n",
        "            )['input_ids'].numpy().ravel())\n",
        "    return torch.from_numpy(np.array(out_encode))\n",
        "\n",
        "model.encode_text = my_encode_text\n",
        "model.transformer = parsbert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnlqXa1SWKAo"
      },
      "source": [
        "## Prepareing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaicwL5UpX11"
      },
      "source": [
        "<div style=\"direction:rtl;\">در این بخش هدف تقسیم داده ها به دسته آموزش، آزمون و اعتبار می باشد.</div>\n",
        "\n",
        "</br>\n",
        "\n",
        "<div style=\"direction:rtl;\">ابتدا کلاس <code>CLIPDataset</code> برای این منظور تعریف شده است که وظیفه این را دارد که متن ها را توکنایز کرده و همچنین پیش‌پردازش لازم را روی تصاویر بزند و در نهایت در خروجی یک تاپل از تصویر و متن مربوطه به آن ارائه کند. سپس با استفاده از تابع <code>train_test_split</code> داده های آموزش و تست و اعتبار از هم جدا شده اند و به این کلاس که گفته شده ارسال شده و در نهایت یک <code>DataLoader</code> براساس هر دسته تعریف شده است که متناسب با اندازه بچ خروجی می هد.</div>\n",
        "\n",
        "</br>\n",
        "\n",
        "<div style=\"direction:rtl;\">هایپرپارامترهای مهم:</div>\n",
        "<ul style=\"direction:rtl;\">\n",
        "    <li>اندازه دسته تست: ۱۵٪ کل داده</li>\n",
        "    <li>اندازه دسته اعتبار: ۱۵٪ داده یادگیری</li>\n",
        "    <li>اندازه بچ: ۶۴</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "f=open(\"news.json\")\n",
        "news=json.load(f)"
      ],
      "metadata": {
        "id": "rLmbX06qUp-A"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess(Image.open(\"images/1400052721030289623422583.jpg\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "T42syBAqX6Qi",
        "outputId": "0db3d8e1-698f-4e8c-e7a3-3e4f5ba0b47d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c0d4e28809d3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"images/1400052721030289623422583.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2975\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: 'images/1400052721030289623422583.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_description_list_final=[]\n",
        "text_title_list_final=[]\n",
        "images_list_final=[]\n",
        "counter=0\n",
        "for item in news:\n",
        "  for image in item.get(\"images\"):\n",
        "    if image==\"1400070516181726323700473.jpg\":\n",
        "      continue\n",
        "    text_description_list_final.append(item.get(\"description\"))\n",
        "    text_title_list_final.append(item.get(\"title\"))\n",
        "    images_list_final.append(\"images/\"+image)\n",
        "   \n",
        "# print(counter)"
      ],
      "metadata": {
        "id": "23HA_SsFYUgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(images_list_final)"
      ],
      "metadata": {
        "id": "mmj2B5578ONX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = pd.DataFrame(preprocess(Image.open(images_list_final[0])).reshape(1,-1))\n",
        "for i in tqdm(range(1024,2048)):\n",
        "  images = images.append(pd.DataFrame(preprocess(Image.open(images_list_final[i])).reshape(1,-1)),ignore_index=True)\n",
        "\n",
        "images.drop(0,axis=0,inplace=True)\n",
        "images.to_csv(\"images2048_pd.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJQY54SFGC2A",
        "outputId": "c6b73cf9-c74f-4f40-fbd2-182483eec729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2048 [00:00<?, ?it/s]<ipython-input-47-e571c50fb04d>:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  images = images.append(pd.DataFrame(preprocess(Image.open(images_list_final[i])).reshape(1,-1)),ignore_index=True)\n",
            " 92%|█████████▏| 1877/2048 [13:59<02:20,  1.22it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splited = [w.split(\" \") for w in text_description_list_final]\n",
        "len(max(splited))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfshg1MX2JO-",
        "outputId": "b903fd48-a7da-4b36-9999-10423f3ea81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = []\n",
        "for i in range(15):\n",
        "  indices.append(random.choice(np.arange(len(images_list_final))))"
      ],
      "metadata": {
        "id": "jj-VPGTb3lDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.image as mpimg\n",
        "\n",
        "for ind in indices:\n",
        "  print(f\"title :{text_title_list_final[ind]}\\ndescription : {text_description_list_final[ind]}\")\n",
        "  img = preprocess(mpimg.imread(images_list_final[ind]))\n",
        "  print(img.shape)\n",
        "  imgplot = plt.imshow(img)\n",
        "  plt.show()\n",
        "  # img = mpimg.imread(images_list_final[ind])\n",
        "  # img = torch.tensor(img).reshape(336,336,3)\n",
        "  # plt.imshow(img.squeeze(),cmap=\"gray\")\n",
        "  # plt.axis(False)\n",
        "  # plt.show()\n",
        "  # plt.imshow(preprocess(Image.open(images_list_final[ind])))"
      ],
      "metadata": {
        "id": "L86VpgFj42ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(images_list_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh62Dz3E4ls5",
        "outputId": "fefc7674-9216-4548-b968-6bf55c36fde9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41382"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slipted = [len(w.split(\" \")) for w in text_title_list_final]\n",
        "plt.hist(slipted)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "AoaYvOmD2PtO",
        "outputId": "915d1dba-e5b2-44b9-915d-9ac6ada1b7f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_list_final[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "11G2x5HF2VC0",
        "outputId": "7a64462d-9da4-4ba1-f00c-8721e01f03ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'images/140008091737564223944593.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITQnDH2JWKAo",
        "outputId": "88425441-f7a6-47a7-b004-0a78d1dc796b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train]\n",
            "> item[0].shape:  torch.Size([64, 3, 336, 336])\n",
            "> item[1].shape:  torch.Size([64, 10])\n",
            "[test]\n",
            "> item[0].shape:  torch.Size([64, 3, 336, 336])\n",
            "> item[1].shape:  torch.Size([64, 10])\n",
            "[val]\n",
            "> item[0].shape:  torch.Size([64, 3, 336, 336])\n",
            "> item[1].shape:  torch.Size([64, 10])\n"
          ]
        }
      ],
      "source": [
        "TEST_SIZE = 0.15\n",
        "VALIDATION_SIZE = 0.15\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "##todo new dataset\n",
        "\n",
        "# class CLIPDataset(Dataset):\n",
        "#     def __init__(self, list_image_path, list_txt):\n",
        "#         self.image_path = list_image_path\n",
        "#         self.text = my_tokenizer(list_txt).to(device)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.text)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         image = preprocess(Image.open(self.image_path[idx]))\n",
        "#         text = self.text[idx]\n",
        "#         return image, text\n",
        "\n",
        "class CLIPDataset(Dataset):\n",
        "    def __init__(self, list_images, list_txt):\n",
        "        self.images = list_images.to(device)\n",
        "        self.text = my_tokenizer(list_txt).to(device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = images[idx]\n",
        "        text = self.text[idx]\n",
        "        return image, text\n",
        "\n",
        "all_df = pd.DataFrame({'text': text_title_list_final, 'image_path': images})\n",
        "\n",
        "train_df, test_df = train_test_split(all_df, test_size=TEST_SIZE, shuffle=True, random_state=42)\n",
        "train_df, val_df = train_test_split(train_df, test_size=VALIDATION_SIZE, shuffle=True, random_state=42)\n",
        "\n",
        "train_dataset = CLIPDataset(train_df['image_path'].tolist(), train_df['text'].tolist())\n",
        "test_dataset = CLIPDataset(test_df['image_path'].tolist(), test_df['text'].tolist())\n",
        "val_dataset = CLIPDataset(val_df['image_path'].tolist(), val_df['text'].tolist())\n",
        "\n",
        "dataloader = {}\n",
        "dataloader['train'] = DataLoader(train_dataset, batch_size = BATCH_SIZE)\n",
        "dataloader['test'] = DataLoader(test_dataset, batch_size = BATCH_SIZE)\n",
        "dataloader['val'] = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
        "\n",
        "# Show shape of data\n",
        "for phase in ['train', 'test', 'val']:\n",
        "    for item in dataloader[phase]:\n",
        "        print(f'[{phase}]')\n",
        "        print(f'> item[0].shape: ', item[0].shape)\n",
        "        print(f'> item[1].shape: ', item[1].shape)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28M9T4XYWKAo"
      },
      "source": [
        "## Fine-tune model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrCqJ4fMpX11"
      },
      "source": [
        "<div style=\"direction:rtl;\">در این بخش قصد داریم تا مدل ساخته شده را با استفاده از دیتاست مان Fine-tune کنیم.</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOBbl_UHpX11"
      },
      "source": [
        "<div style=\"direction:rtl;\">ابتدا لازم است تا یک سری از هایپرپارامترها را در این بخش تعیین کنیم:</div>\n",
        "</br>\n",
        "\n",
        "| Hyper-paremeter                                         | Value                                               |\n",
        "| ------------------------------------------------------- | --------------------------------------------------- |\n",
        "| Number of Epochs [EPOCH]                                |   10                                                |\n",
        "| Learning-Rate [LR]                                      |   1e-7                                              |\n",
        "| Eps for Adam-optimizer [EPS]                            |   1e-9                                              |\n",
        "| Weight decay of Adam-optimizer [WEIGHT_DECAY]           |   0.1                                               |\n",
        "| Maximum of learning-rate value for scheduler [MAX_LR]   |   1e-2                                              |\n",
        "| Optimizer                                               |   Adam                                              |\n",
        "| Learning-rate scheduler [scheduler]                     |   OneCycleLR                                        |\n",
        "| Image and text prediction loss                          |   CrossEntropyLoss                                  |\n",
        "| Number of freeze layers                                 |   20 layer of each module (visual and transformer)  |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE-R41RezF8H"
      },
      "outputs": [],
      "source": [
        "# !mkdir /content/drive/MyDrive/clip_trained_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32H5ab1nl_QZ"
      },
      "outputs": [],
      "source": [
        "EPOCH = 10\n",
        "LR = 1e-7\n",
        "EPS = 1e-9\n",
        "WEIGHT_DECAY = 0.1\n",
        "MAX_LR = 1e-2\n",
        "BASE_MODEL_PATH = '/content/drive/MyDrive/TasnimDataset/models/clip_trained_model/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-La7qSMVWIZ"
      },
      "outputs": [],
      "source": [
        "loss_img = nn.CrossEntropyLoss()\n",
        "loss_txt = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), \n",
        "                             lr=LR,\n",
        "                             betas=(0.9,0.98),\n",
        "                             eps=EPS,\n",
        "                             weight_decay=WEIGHT_DECAY) \n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
        "                                                max_lr=MAX_LR, \n",
        "                                                steps_per_epoch=len(dataloader['train']), \n",
        "                                                epochs=EPOCH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gkQhih_ebp1"
      },
      "source": [
        "<div style=\"direction:rtl;\">در این بخش مدل زبانی و مدل تصویر ۲۰ لایه آخر به حالت قابل آموزش هستند و بقیه مدل فریز شده است:</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1HXx-XHpX12"
      },
      "outputs": [],
      "source": [
        "layer_num = [0, 0]\n",
        "freeze_layer_thr = 30\n",
        "freeze_layer_txt_thr = 20\n",
        "\n",
        "for param in model.transformer.parameters():\n",
        "    layer_num[0]+=1\n",
        "for param in model.visual.parameters():\n",
        "    layer_num[1]+=1\n",
        "\n",
        "for i, param in enumerate(model.transformer.parameters()):\n",
        "    if freeze_layer_txt_thr >= layer_num[0] - i:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "for i, param in enumerate(model.visual.parameters()):\n",
        "    if freeze_layer_thr >= layer_num[1] - i:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZF7V8dlpX12"
      },
      "source": [
        "<div style=\"direction:rtl;\">فرآیند آموزش به این شکل است که دارای دو فاز آموزش و اعتبار می باشد، در فاز آموزش گرادیان ها حساب شده و مراحل backpropagation انجام می شود ولی در فاز اعتبار صرفا بررسی می شود که مقدار loss چقدر است برای این داده ها، به نوعی برای مشخص کردن محلی است که مدل به اندازه کافی خوب شده است. که در این آموزش در ایپاک ۴ مدل خوب شده است.</div>\n",
        "\n",
        "</br>\n",
        "\n",
        "<div style=\"direction:rtl;\">به منظور محاسبه loss در هنگام یادگیری، مطابق با <a href=\"https://arxiv.org/abs/2103.00020\">مقاله CLIP</a> فرآیند انجام شده است:</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "<p align=\"center\"><img src=\"https://github.com/AAhmadS/NLP-HW3/blob/data/clip_train_loss.png?raw=1\" width=60% /></p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHNzRPPOWKAp"
      },
      "outputs": [],
      "source": [
        "def train_model(model, optimizer, scheduler, num_epochs=10):\n",
        "    since = time.time()\n",
        "\n",
        "    for epoch in range(1, num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        best_val_loss = 10000000 \n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            total_loss = 0.0\n",
        "            num = 0\n",
        "\n",
        "            for batch in tqdm(dataloader[phase]):\n",
        "                optimizer.zero_grad()\n",
        "                images, texts = batch\n",
        "                images = images.to(device)\n",
        "                texts = texts.to(device)\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    logits_per_image, logits_per_text = model(images, texts)\n",
        "                    ground_truth = torch.arange(len(images),dtype=torch.long,device=device)\n",
        "                    batch_loss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        batch_loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                total_loss += batch_loss\n",
        "                num += 1\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = total_loss / num\n",
        "            \n",
        "            if phase == 'val':\n",
        "              if epoch_loss < best_val_loss:\n",
        "                best_val_loss = epoch_loss\n",
        "                torch.save(model.state_dict(), BASE_MODEL_PATH+f'clip_en_fi_ep.pt')\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f}')\n",
        "\n",
        "            # if phase == 'train':\n",
        "            #     torch.save(model.state_dict(), BASE_MODEL_PATH+f'clip_en_fi_ep{epoch}.pt')\n",
        "            \n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XQlseyeskc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "1ed263f5-d55e-4869-e347-34b4de77c966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 24/468 [05:21<1:39:05, 13.39s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-451e4ab274b9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-98-4239ca1ab65f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-81-1caca3cedf2e>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2975\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images/1398010411504489816996274.jpg'"
          ]
        }
      ],
      "source": [
        "train_model(model=model, optimizer=optimizer, scheduler=scheduler, num_epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCZ36VtTDp20"
      },
      "source": [
        "<div style=\"direction:rtl;\">به دلیل این که دسترسی به کولب قطع شد، ۴ ایپاک اول روی اجرای قبلی بود عکس آن ضمیمه شد.</div>\n",
        "<br>\n",
        "\n",
        "<p align=\"center\"><img src=\"https://github.com/AAhmadS/NLP-HW3/blob/data/train_first_4epoch.png?raw=1\" width=60% /></p>"
      ]
    }
  ]
}